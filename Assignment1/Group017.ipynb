{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 1 in Assessment 1\n",
    "\n",
    "#### Group number: 17\n",
    "#### Student Names: Roopesh Kumar Ramesh, Nikita Mary John\n",
    "#### Student ID: 30344565, 30142776\n",
    "\n",
    "Date: 25/08/2019\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: \n",
    "* pandas (for dataframe, included in Anaconda Python 3) \n",
    "* re (for regular expressions, included in Anaconda Python 3) \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The aim of this assignment is to parse through a text file in xml format, extract data and write this data to a csv and a json file. The given text file contains information about various grants given for IP patent claims. We are required to extract grant_id, patent_kind, patent_title, number_of_claims, citations_examiner_count, citations_applicant_count, inventors, claims_text and abstract. In the text file provided to us, there are a total of 150 grant entries. \n",
    "\n",
    "NOTE: In order for the following code to run, the input text file must be stored in the same folder as this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the course of this assignment, we used the pandas and re libraries extensively. The pandas library was used to create the dataframe which we then wrote to a csv file. The re library was used to extract the required data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Examining and loading data\n",
    "\n",
    "First, we opened the text file and stored its contents as a string in \"text\". We then used a regular expression and the re library to extract each block that represented one patent grant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('Group017.txt','r') \n",
    "text = file.read() #storing the entire file as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that each entry began with \"<\\?xml version=\"1.0\" encoding=\"UTF-8\"\\?>\" and ended with \"</us-patent-grant>\". We used this to extract each entry and store them as an element of the list 'patents'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r'<\\?xml version=\"1.0\" encoding=\"UTF-8\"\\?>.*?</us-patent-grant>' \n",
    "patents = re.findall(regex, text, flags=16) #the findall function returns a list of everything matching the specified pattern\n",
    "len(patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then checked the length of the list obtained above and came to the conclusion that the text file contains 150 data entries. We finially printed the first entry and examined it in order to find patters to extract the required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<us-patent-grant lang=\"EN\" dtd-version=\"v4.5 2014-04-03\" file=\"US10359846-20190723.XML\" status=\"PRODUCTION\" id=\"us-patent-grant\" country=\"US\" date-produced=\"20190709\" date-publ=\"20190723\">\n",
      "<us-bibliographic-data-grant>\n",
      "<publication-reference>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>10359846</doc-number>\n",
      "<kind>B2</kind>\n",
      "<date>20190723</date>\n",
      "</document-id>\n",
      "</publication-reference>\n",
      "<application-reference appl-type=\"utility\">\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>16005056</doc-number>\n",
      "<date>20180611</date>\n",
      "</document-id>\n",
      "</application-reference>\n",
      "<us-application-series-code>16</us-application-series-code>\n",
      "<classifications-ipcr>\n",
      "<classification-ipcr>\n",
      "<ipc-version-indicator><date>20060101</date></ipc-version-indicator>\n",
      "<classification-level>A</classification-level>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>3</main-group>\n",
      "<subgroup>01</subgroup>\n",
      "<symbol-position>F</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "</classification-ipcr>\n",
      "<classification-ipcr>\n",
      "<ipc-version-indicator><date>20060101</date></ipc-version-indicator>\n",
      "<classification-level>A</classification-level>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>3</main-group>\n",
      "<subgroup>041</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "</classification-ipcr>\n",
      "<classification-ipcr>\n",
      "<ipc-version-indicator><date>20060101</date></ipc-version-indicator>\n",
      "<classification-level>A</classification-level>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>1</main-group>\n",
      "<subgroup>16</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "</classification-ipcr>\n",
      "</classifications-ipcr>\n",
      "<classifications-cpc>\n",
      "<main-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>3</main-group>\n",
      "<subgroup>014</subgroup>\n",
      "<symbol-position>F</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "</main-cpc>\n",
      "<further-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>1</main-group>\n",
      "<subgroup>163</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>1</main-group>\n",
      "<subgroup>1698</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>3</main-group>\n",
      "<subgroup>017</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>3</main-group>\n",
      "<subgroup>041</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>I</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "<classification-cpc>\n",
      "<cpc-version-indicator><date>20130101</date></cpc-version-indicator>\n",
      "<section>G</section>\n",
      "<class>06</class>\n",
      "<subclass>F</subclass>\n",
      "<main-group>2203</main-group>\n",
      "<subgroup>0331</subgroup>\n",
      "<symbol-position>L</symbol-position>\n",
      "<classification-value>A</classification-value>\n",
      "<action-date><date>20190723</date></action-date>\n",
      "<generating-office><country>US</country></generating-office>\n",
      "<classification-status>B</classification-status>\n",
      "<classification-data-source>H</classification-data-source>\n",
      "<scheme-origination-code>C</scheme-origination-code>\n",
      "</classification-cpc>\n",
      "</further-cpc>\n",
      "</classifications-cpc>\n",
      "<invention-title id=\"d2e43\">Wearable device gesture detection</invention-title>\n",
      "<us-references-cited>\n",
      "<us-citation>\n",
      "<patcit num=\"00001\">\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>2011/0080339</doc-number>\n",
      "<kind>A1</kind>\n",
      "<name>Sun</name>\n",
      "<date>20110400</date>\n",
      "</document-id>\n",
      "</patcit>\n",
      "<category>cited by examiner</category>\n",
      "<classification-cpc-text>G06F 3/017</classification-cpc-text>\n",
      "<classification-national><country>US</country><main-classification>345157</main-classification></classification-national>\n",
      "</us-citation>\n",
      "<us-citation>\n",
      "<patcit num=\"00002\">\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>2014/0028539</doc-number>\n",
      "<kind>A1</kind>\n",
      "<name>Newham</name>\n",
      "<date>20140100</date>\n",
      "</document-id>\n",
      "</patcit>\n",
      "<category>cited by examiner</category>\n",
      "<classification-cpc-text>G06F 1/1694</classification-cpc-text>\n",
      "<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>\n",
      "</us-citation>\n",
      "</us-references-cited>\n",
      "<number-of-claims>20</number-of-claims>\n",
      "<us-exemplary-claim>1</us-exemplary-claim>\n",
      "<us-field-of-classification-search>\n",
      "<classification-cpc-text>G06F 3/014</classification-cpc-text>\n",
      "<classification-cpc-text>G06F 1/1698</classification-cpc-text>\n",
      "<classification-cpc-text>G06F 1/163</classification-cpc-text>\n",
      "<classification-cpc-text>G06F 3/017</classification-cpc-text>\n",
      "<classification-cpc-text>G06F 3/041</classification-cpc-text>\n",
      "<classification-cpc-text>G06F 2203/0331</classification-cpc-text>\n",
      "</us-field-of-classification-search>\n",
      "<figures>\n",
      "<number-of-drawing-sheets>8</number-of-drawing-sheets>\n",
      "<number-of-figures>9</number-of-figures>\n",
      "</figures>\n",
      "<us-related-documents>\n",
      "<continuation>\n",
      "<relation>\n",
      "<parent-doc>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>15223887</doc-number>\n",
      "<date>20160729</date>\n",
      "</document-id>\n",
      "<parent-grant-document>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>10191543</doc-number>\n",
      "</document-id>\n",
      "</parent-grant-document>\n",
      "</parent-doc>\n",
      "<child-doc>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>16005056</doc-number>\n",
      "</document-id>\n",
      "</child-doc>\n",
      "</relation>\n",
      "</continuation>\n",
      "<continuation>\n",
      "<relation>\n",
      "<parent-doc>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>14286910</doc-number>\n",
      "<date>20140523</date>\n",
      "</document-id>\n",
      "<parent-grant-document>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>9594427</doc-number>\n",
      "<date>20170314</date>\n",
      "</document-id>\n",
      "</parent-grant-document>\n",
      "</parent-doc>\n",
      "<child-doc>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>15223887</doc-number>\n",
      "</document-id>\n",
      "</child-doc>\n",
      "</relation>\n",
      "</continuation>\n",
      "<related-publication>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>20180292901</doc-number>\n",
      "<kind>A1</kind>\n",
      "<date>20181011</date>\n",
      "</document-id>\n",
      "</related-publication>\n",
      "</us-related-documents>\n",
      "<us-parties>\n",
      "<us-applicants>\n",
      "<us-applicant sequence=\"001\" app-type=\"applicant\" designation=\"us-only\" applicant-authority-category=\"assignee\">\n",
      "<addressbook>\n",
      "<orgname>Microsoft Technology Licensing, LLC</orgname>\n",
      "<address>\n",
      "<city>Redmond</city>\n",
      "<state>WA</state>\n",
      "<country>US</country>\n",
      "</address>\n",
      "</addressbook>\n",
      "<residence>\n",
      "<country>US</country>\n",
      "</residence>\n",
      "</us-applicant>\n",
      "</us-applicants>\n",
      "<inventors>\n",
      "<inventor sequence=\"001\" designation=\"us-only\">\n",
      "<addressbook>\n",
      "<last-name>Priyantha</last-name>\n",
      "<first-name>Nissanka Arachchige Bodhi</first-name>\n",
      "<address>\n",
      "<city>Redmond</city>\n",
      "<state>WA</state>\n",
      "<country>US</country>\n",
      "</address>\n",
      "</addressbook>\n",
      "</inventor>\n",
      "<inventor sequence=\"002\" designation=\"us-only\">\n",
      "<addressbook>\n",
      "<last-name>Liu</last-name>\n",
      "<first-name>Jie</first-name>\n",
      "<address>\n",
      "<city>Medina</city>\n",
      "<state>WA</state>\n",
      "<country>US</country>\n",
      "</address>\n",
      "</addressbook>\n",
      "</inventor>\n",
      "</inventors>\n",
      "<agents>\n",
      "<agent sequence=\"01\" rep-type=\"attorney\">\n",
      "<addressbook>\n",
      "<orgname>Rainier Patents, P.S.</orgname>\n",
      "<address>\n",
      "<country>unknown</country>\n",
      "</address>\n",
      "</addressbook>\n",
      "</agent>\n",
      "</agents>\n",
      "</us-parties>\n",
      "<assignees>\n",
      "<assignee>\n",
      "<addressbook>\n",
      "<orgname>Microsoft Technology Licensing, LLC</orgname>\n",
      "<role>02</role>\n",
      "<address>\n",
      "<city>Redmond</city>\n",
      "<state>WA</state>\n",
      "<country>US</country>\n",
      "</address>\n",
      "</addressbook>\n",
      "</assignee>\n",
      "</assignees>\n",
      "<examiners>\n",
      "<primary-examiner>\n",
      "<last-name>Sasinowski</last-name>\n",
      "<first-name>Andrew</first-name>\n",
      "<department>2625</department>\n",
      "</primary-examiner>\n",
      "</examiners>\n",
      "</us-bibliographic-data-grant>\n",
      "<abstract id=\"abstract\">\n",
      "<p id=\"p-0001\" num=\"0000\">The description relates to smart rings. One example can include a finger band configured to accommodate a user's finger. This example can also include a set of pressure sensors positioned on an inner surface of the finger band and configured to sense changes to tendons of the user's finger as pressure differentials and to output associated signals. The example can further include a gesture component configured to interpret the signals from the set of pressure sensors to identify individual actions performed by the user's finger.</p>\n",
      "</abstract>\n",
      "<drawings id=\"DRAWINGS\">\n",
      "<figure id=\"Fig-EMI-D00000\" num=\"00000\">\n",
      "<img id=\"EMI-D00000\" he=\"115.74mm\" wi=\"158.75mm\" file=\"US10359846-20190723-D00000.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00001\" num=\"00001\">\n",
      "<img id=\"EMI-D00001\" he=\"255.95mm\" wi=\"172.89mm\" file=\"US10359846-20190723-D00001.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00002\" num=\"00002\">\n",
      "<img id=\"EMI-D00002\" he=\"253.92mm\" wi=\"183.47mm\" file=\"US10359846-20190723-D00002.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00003\" num=\"00003\">\n",
      "<img id=\"EMI-D00003\" he=\"259.25mm\" wi=\"185.50mm\" file=\"US10359846-20190723-D00003.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00004\" num=\"00004\">\n",
      "<img id=\"EMI-D00004\" he=\"258.91mm\" wi=\"164.34mm\" file=\"US10359846-20190723-D00004.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00005\" num=\"00005\">\n",
      "<img id=\"EMI-D00005\" he=\"257.22mm\" wi=\"187.11mm\" orientation=\"landscape\" file=\"US10359846-20190723-D00005.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00006\" num=\"00006\">\n",
      "<img id=\"EMI-D00006\" he=\"193.46mm\" wi=\"195.75mm\" file=\"US10359846-20190723-D00006.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00007\" num=\"00007\">\n",
      "<img id=\"EMI-D00007\" he=\"185.17mm\" wi=\"189.15mm\" file=\"US10359846-20190723-D00007.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "<figure id=\"Fig-EMI-D00008\" num=\"00008\">\n",
      "<img id=\"EMI-D00008\" he=\"174.92mm\" wi=\"186.52mm\" file=\"US10359846-20190723-D00008.TIF\" alt=\"embedded image\" img-content=\"drawing\" img-format=\"tif\"/>\n",
      "</figure>\n",
      "</drawings>\n",
      "<description id=\"description\">\n",
      "<?BRFSUM description=\"Brief Summary\" end=\"lead\"?>\n",
      "<heading id=\"h-0001\" level=\"1\">BACKGROUND</heading>\n",
      "<p id=\"p-0002\" num=\"0001\">Increasingly users interact with their mobile devices on the go. Many users continuously utilize various device applications. For instance, users listen to music on mobile devices while traveling, and constantly check E-mails. Shoppers browse through their shopping lists and do price comparisons while shopping, among others.</p>\n",
      "<p id=\"p-0003\" num=\"0002\">Interacting with mobile devices on-the-go tends to require the user to enter different gestures to scroll, zoom, flip, and/or enter text on graphical user interface (GUI) elements. The smart phone with its relatively large display has provided a unified and convenient platform for such interactions. However, more recent trends in wearable devices such as glasses, wrist bands, and watches have made such interactions limited and awkward due to the lack of touch real estate and the positioning of the device itself.</p>\n",
      "<p id=\"p-0004\" num=\"0003\">While mobile device interfaces continue to shrink, interfaces of remote display devices such as TVs and game consoles are becoming even more complex, requiring extensive maneuvering via simple remote controllers or requiring remote control with full keyboard-like capability. For example, with a conventional remote control, a simple task such as entering text to search for a movie title becomes a monumental task leading to a poor user experience.</p>\n",
      "<heading id=\"h-0002\" level=\"1\">SUMMARY</heading>\n",
      "<p id=\"p-0005\" num=\"0004\">The description relates to smart rings. One example can include a finger band configured to accommodate a user's finger. This example can also include a set of pressure sensors positioned on an inner surface of the finger band and configured to sense changes to tendons of the user's finger as pressure differentials and to output associated signals. The example can further include a gesture component configured to interpret the signals from the set of pressure sensors to identify individual actions performed by the user's finger.</p>\n",
      "<p id=\"p-0006\" num=\"0005\">The above listed example is intended to provide a quick reference to aid the reader and is not intended to define the scope of the concepts described herein.</p>\n",
      "<?BRFSUM description=\"Brief Summary\" end=\"tail\"?>\n",
      "<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?>\n",
      "<description-of-drawings>\n",
      "<heading id=\"h-0003\" level=\"1\">BRIEF DESCRIPTION OF THE DRAWINGS</heading>\n",
      "<p id=\"p-0007\" num=\"0006\">The accompanying drawings illustrate implementations of the concepts conveyed in the present document. Features of the illustrated implementations can be more readily understood by reference to the following description taken in conjunction with the accompanying drawings. Like reference numbers in the various drawings are used wherever feasible to indicate like elements. Further, the left-most numeral of each reference number conveys the FIG. and associated discussion where the reference number is first introduced.</p>\n",
      "<p id=\"p-0008\" num=\"0007\"><figref idref=\"DRAWINGS\">FIGS. 1 and 2</figref> collectively show example smart ring applications in accordance with some implementations of the present concepts.</p>\n",
      "<p id=\"p-0009\" num=\"0008\"><figref idref=\"DRAWINGS\">FIGS. 3-5</figref> show example smart ring use case scenarios in accordance with some implementations of the present concepts.</p>\n",
      "<p id=\"p-0010\" num=\"0009\"><figref idref=\"DRAWINGS\">FIG. 6</figref> shows a system example in accordance with some implementations of the present concepts.</p>\n",
      "<p id=\"p-0011\" num=\"0010\"><figref idref=\"DRAWINGS\">FIG. 7</figref> shows stroke gesture primitives that can be utilized in accordance with some implementations of the present concepts.</p>\n",
      "<p id=\"p-0012\" num=\"0011\"><figref idref=\"DRAWINGS\">FIG. 8</figref> shows a state diagram that can be utilized in accordance with some implementations of the present concepts.</p>\n",
      "<p id=\"p-0013\" num=\"0012\"><figref idref=\"DRAWINGS\">FIG. 9</figref> shows an example flow chart in accordance with some implementations of the present concepts.</p>\n",
      "</description-of-drawings>\n",
      "<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?>\n",
      "<?DETDESC description=\"Detailed Description\" end=\"lead\"?>\n",
      "<heading id=\"h-0004\" level=\"1\">OVERVIEW</heading>\n",
      "<p id=\"p-0014\" num=\"0013\">The present concepts relate to allowing a user to use his/her fingers to control a device. The implementations relate to a wearable ring platform (e.g., smart ring) worn on one or more of the user's fingers. (As used herein, the term &#x2018;finger&#x2019; can include the &#x2018;thumb&#x2019;). The smart ring can detect and interpret various control gestures or actions performed by the user. The smart ring can wirelessly transmit the control gestures to the device. As used herein any action that can be performed by one or more fingers can be thought of as a gesture. Thus, the action of touching a surface with the finger can be an example of a gesture. Similarly, touching and sliding the finger on a surface can be a gesture. Moving the finger in the air or bending the finger can be a gesture. Further, the action of waving with one or more fingers can be a gesture. Actions performed by both hands can also be a gesture. In summary, actions can include touch gestures and non-touch gestures and/or single finger gestures and multi-finger gestures. Further examples of actions (e.g., gestures) are described below.</p>\n",
      "<p id=\"p-0015\" num=\"0014\">Introductory <figref idref=\"DRAWINGS\">FIGS. 1-2</figref> show a human hand <b>100</b>. Most of the hand is covered with skin <b>102</b>. However, for purposes of explanation, the skin is not shown for a portion of the hand relating to the index finger <b>104</b> to allow visualization of the underlying tissues. More specifically, tendons <b>106</b> are visible on the index finger. These tendons can move when the finger moves or when the finger imparts a force on a surface. <figref idref=\"DRAWINGS\">FIG. 2</figref> introduces a pressure sensitive smart ring (or &#x2018;smart ring device&#x2019; or &#x2018;smart ring&#x2019;) <b>202</b> positioned on the user's index finger. The pressure sensitive smart ring can include elements for detecting changes to the tendons. Examples of these elements are discussed in more detail below relative to <figref idref=\"DRAWINGS\">FIG. 6</figref>. (Note that to avoid clutter on the drawing page, on <figref idref=\"DRAWINGS\">FIG. 2</figref>, the tendon <b>106</b> lead line only goes to one of the tendons rather than two in <figref idref=\"DRAWINGS\">FIG. 1</figref>).</p>\n",
      "<p id=\"p-0016\" num=\"0015\"><figref idref=\"DRAWINGS\">FIG. 3</figref> shows a first use case scenario <b>300</b> involving a user <b>302</b> wearing an example of pressure sensitive smart ring <b>202</b>. In this case the user is engaging a digital display device <b>304</b>. In this example, the digital display device includes a depth sensor <b>306</b>. In some implementations the depth sensor can be manifest as a red, green, blue, plus depth (RGBD) camera. Various types of visible light, non-visible light, and/or sonic depth sensors, among others can be employed.</p>\n",
      "<p id=\"p-0017\" num=\"0016\">The depth sensor <b>306</b> can be useful in detecting the presence of user <b>302</b> in front of the digital display device <b>304</b> and detecting gestures performed by the user in front of the digital display device. However, the depth sensor may not be able to accurately detect user actions close to the digital display device. For instance, the depth sensor may not be able to distinguish whether the user is pointing at a location on the digital display device or touching the location on the digital display device. The pressure sensitive smart ring <b>202</b> can determine whether the user's finger is touching a surface as indicated by &#x2018;starburst&#x2019; <b>308</b>. Further, the pressure sensitive smart ring <b>202</b> can determine that while touching the surface the finger is moving in a downward direction as indicated by arrow <b>310</b>. Data from the depth sensor <b>306</b> and the pressure sensitive smart ring <b>202</b> can detect user gestures in front of the digital display device as well as user contact of the digital display device. Thus, the pressure sensitive smart ring <b>202</b> and the depth sensor <b>306</b> can collectively provide information that can allow the digital display device to function in a manner similar to a touch sensitive display device without actually being &#x2018;touch sensitive.&#x2019;</p>\n",
      "<p id=\"p-0018\" num=\"0017\"><figref idref=\"DRAWINGS\">FIG. 4</figref> shows another use case scenario <b>400</b> that is similar to the use case scenario of <figref idref=\"DRAWINGS\">FIG. 3</figref>. In this case, the pressure sensitive smart ring <b>202</b> can operate cooperatively with smart glasses <b>402</b> to provide information about user <b>302</b>. For instance, the smart glasses can capture information about what is in front of the user. In this example, the smart glasses can &#x2018;see&#x2019; content on the digital display device <b>304</b>. The smart glasses may be less effective at determining whether the user <b>302</b> is touching the digital display device <b>304</b>. However, as explained above relative to <figref idref=\"DRAWINGS\">FIG. 3</figref>, the pressure sensitive smart ring <b>202</b> can accurately determine whether the user is touching the digital display device. The pressure sensitive smart ring <b>202</b> and the smart glasses <b>402</b> can communicate with the digital display device <b>304</b> to detect user gestures (both touch and non-touch) to provide an enhanced interactive experience to the user.</p>\n",
      "<p id=\"p-0019\" num=\"0018\"><figref idref=\"DRAWINGS\">FIG. 5</figref> shows another use case scenario <b>500</b> at instance one, instance two, and instance three. Scenario <b>500</b> involves pressure sensitive smart rings <b>202</b>(<b>1</b>) and <b>202</b>(<b>2</b>) and a smart watch <b>502</b>. Pressure sensitive smart ring <b>202</b>(<b>1</b>) is positioned on the user's index finger <b>104</b> and pressure sensitive smart ring <b>202</b>(<b>2</b>) is positioned on the user's middle finger. Instance one shows the user touching the smart watch with his index finger <b>104</b>. This touch can be detected by pressure sensitive smart ring <b>202</b>(<b>1</b>). This touch can be interpreted as a first user command, such as to select an application to run on the smart watch.</p>\n",
      "<p id=\"p-0020\" num=\"0019\">Instance two shows the user performing a non-touch command by bending the index finger <b>104</b> at the middle joint. This non-touch command can be detected by pressure sensitive smart ring <b>202</b>(<b>1</b>) and distinguished by the smart ring from the command of instance one by a pressure profile (e.g., which pressure sensors detect pressure). This command could be interpreted as a scroll down command by the smart watch, for example.</p>\n",
      "<p id=\"p-0021\" num=\"0020\">Instance three shows a similar non-touch command to instance two except that it is performed by both the index finger and the middle finger (e.g. a multi-finger gesture) and detected by pressure sensitive smart ring <b>202</b>(<b>1</b>) and pressure sensitive smart ring <b>202</b>(<b>2</b>). This command could be interpreted as a &#x2018;select&#x2019; command by the smart watch, for example. Mechanisms for accomplishing this functionality are described below relative to <figref idref=\"DRAWINGS\">FIG. 6</figref>.</p>\n",
      "<p id=\"p-0022\" num=\"0021\"><figref idref=\"DRAWINGS\">FIG. 6</figref> shows a gesture detection system <b>600</b>. For purposes of explanation, system <b>600</b> includes pressure sensitive smart ring <b>202</b>, digital display device <b>304</b>, depth sensor <b>306</b>, smart glasses <b>402</b>, smart watch <b>502</b>, and a smart phone <b>602</b>. Any of these devices can communicate over one or more networks <b>604</b>.</p>\n",
      "<p id=\"p-0023\" num=\"0022\">Two configurations <b>606</b>(<b>1</b>) and <b>606</b>(<b>2</b>) are illustrated for pressure sensitive smart ring <b>202</b>. Briefly, configuration <b>606</b>(<b>1</b>) represents an operating system centric configuration and configuration <b>606</b>(<b>2</b>) represents a system on a chip configuration. Configuration <b>606</b>(<b>1</b>) is organized into one or more applications <b>610</b>, operating system <b>612</b>, and hardware <b>614</b>. Configuration <b>606</b>(<b>2</b>) is organized into shared resources <b>616</b>, dedicated resources <b>618</b>, and an interface <b>620</b> there between.</p>\n",
      "<p id=\"p-0024\" num=\"0023\">In either configuration, the pressure sensitive smart ring <b>202</b> can include storage <b>622</b>, a processor <b>624</b>, a battery <b>626</b> (or other power source), a battery charger <b>628</b>, sensors <b>630</b>, a communication component <b>632</b>, and/or a gesture component <b>634</b>. These elements can be positioned in/on or otherwise associated with a physical finger band <b>636</b>. For instance, the elements can be positioned within the finger band <b>636</b> so that the pressure sensitive smart ring <b>202</b> has the general appearance of a traditional &#x2018;jewelry&#x2019; ring. The finger band <b>636</b> can be formed of various materials such as plastics, polymers, and/or natural materials such as jade or other minerals. The pressure sensitive smart ring <b>202</b> can also include ornamental aspects such as precious stones to mimic a traditional jewelry ring.</p>\n",
      "<p id=\"p-0025\" num=\"0024\">From one perspective, any of pressure sensitive smart ring <b>202</b>, digital display device <b>304</b>, depth sensor <b>306</b>, smart glasses <b>402</b>, smart watch <b>502</b>, and/or smart phone <b>602</b> can be thought of as computers.</p>\n",
      "<p id=\"p-0026\" num=\"0025\">The term &#x201c;device,&#x201d; &#x201c;computer,&#x201d; or &#x201c;computing device&#x201d; as used herein can mean any type of device that has some amount of processing capability and/or storage capability. Processing capability can be provided by one or more processors that can execute data in the form of computer-readable instructions to provide a functionality. Data, such as computer-readable instructions and/or user-related data, can be stored on storage, such as storage that can be internal or external to the computer. The storage can include any one or more of volatile or non-volatile memory, hard drives, flash storage devices, and/or optical storage devices (e.g., CDs, DVDs etc.), remote storage (e.g., cloud-based storage), among others. As used herein, the term &#x201c;computer-readable media&#x201d; can include signals. In contrast, the term &#x201c;computer-readable storage media&#x201d; excludes signals. Computer-readable storage media includes &#x201c;computer-readable storage devices.&#x201d; Examples of computer-readable storage devices include volatile storage media, such as RAM, and non-volatile storage media, such as hard drives, optical discs, and/or flash memory, among others.</p>\n",
      "<p id=\"p-0027\" num=\"0026\">As mentioned above, configuration <b>606</b>(<b>2</b>) can be thought of as a system on a chip (SOC) type design. In such a case, functionality provided by the device can be integrated on a single SOC or multiple coupled SOCs. One or more processors can be configured to coordinate with shared resources, such as memory, storage, etc., and/or one or more dedicated resources, such as hardware blocks configured to perform certain specific functionality. Thus, the term &#x201c;processor&#x201d; as used herein can also refer to central processing units (CPU), graphical processing units (CPUs), controllers, microcontrollers, processor cores, or other types of processing devices.</p>\n",
      "<p id=\"p-0028\" num=\"0027\">Generally, any of the functions described herein can be implemented using software, firmware, hardware (e.g., fixed-logic circuitry), manual processing, or a combination of these implementations. The term &#x201c;component&#x201d; as used herein generally represents software, firmware, hardware, whole devices or networks, or a combination thereof. In the case of a software implementation, for instance, these may represent program code that performs specified tasks when executed on a processor (e.g., CPU or CPUs). The program code can be stored in one or more computer-readable memory devices, such as computer-readable storage media. The features and techniques of the component are platform-independent, meaning that they may be implemented on a variety of commercial computing platforms having a variety of processing configurations.</p>\n",
      "<p id=\"p-0029\" num=\"0028\">The battery <b>626</b> can be charged in various ways by the battery charger <b>628</b>. In one instance, the battery charger is manifest as a wireless inductive charger. The wireless inductive charger can include multiple conductive coils wrapping around the pressure sensitive smart ring <b>202</b>, such as following the ring shape of the finger band <b>636</b>. In other configurations the coils can be associated with the ring but not coiled around the ring. For instance, small coils can be contained within the finger band or otherwise associated with the finger band. The wireless inductive charger can capture magnetic energy from wireless chargers. The wireless chargers can be included in any of digital display device <b>304</b>, depth sensor <b>306</b>, smart glasses <b>402</b>, smart watch <b>502</b>, smart phone <b>602</b>, and/or other devices. Beyond the charging facet, the wireless inductive charging feature can provide a proximity sensing function for the two devices. For instance, when the user places his hand with the pressure sensitive smart ring <b>202</b> near the smart phone <b>602</b>, the wireless inductive charger can detect the magnetic field of the smart phone and thus indicate to the pressure sensitive smart ring <b>202</b> that it is proximate to the smart phone. Similarly, the entry of the pressure sensitive smart ring <b>202</b> into the magnetic field generated by the smart phone can indicate to the smart phone that the pressure sensitive smart ring <b>202</b> is proximate to the smart phone. In summary, some pressure sensitive smart ring implementations can opportunistically harvest energy from an NFC-enabled companion device, such as devices <b>304</b>, <b>306</b>, <b>402</b>, <b>502</b>, and/or <b>602</b>, among others for perpetual operation without explicit charging.</p>\n",
      "<p id=\"p-0030\" num=\"0029\">Further, powering sensors and analyzing sensor data consumes power. The gesture component <b>634</b> can manage the sensors <b>630</b>, battery <b>626</b>, processor <b>624</b>, and/or other components to conserve resources. In other configurations a power management controller (not shown) may manage the components. Several techniques for conserving power usage are described below.</p>\n",
      "<p id=\"p-0031\" num=\"0030\">Multiple types of sensors <b>630</b> can be included in the pressure sensitive smart ring <b>202</b>. Of course, the sensors can include pressure sensors <b>638</b>. In this example, three pressure sensors are illustrated positioned on an inner surface <b>640</b> (e.g., inwardly facing surface) of the finger band <b>636</b>. In this case, when the pressure sensitive smart ring <b>202</b> is worn by the user, pressure sensor <b>638</b>(<b>1</b>) is configured to be positioned at the 8-9 o'clock position (with the diamond at the top of the ring acting as 12 o'clock). Pressure sensor <b>638</b>(<b>2</b>) is configured to be positioned at the 6 o'clock position and pressure sensor <b>638</b>(<b>3</b>) is configured to be positioned at the 3-4 o'clock position. Of course, other numbers and/or positions of pressure sensors can be employed. For example, a radial array of pressure sensors could be positioned on the inside surface of the ring so that even if the ring spins on the user's finger, pressure detected by generally opposing pressure sensors can be indicative of a touch gesture. Examples of pressure sensors can include force sensitive resistors and/or piezoelectric sensors, among others. In some cases the pressure sensor can be coupled to a low power comparator and controlled by power gating as determined by the gesture component <b>634</b>.</p>\n",
      "<p id=\"p-0032\" num=\"0031\">Sensors <b>630</b> can also include accelerometers, gyroscopes, magnetometers, and/or microphones, among others. For instance, the implementation of <figref idref=\"DRAWINGS\">FIG. 4</figref> can include pressure sensors to detect contact with the surface and accelerometers to detect the downward movement. While not shown in <figref idref=\"DRAWINGS\">FIG. 4</figref>, the gyros could further detect &#x2018;twisting&#x2019; of the pressure sensitive smart ring <b>202</b> to allow a straight down movement to be distinguished from a down and to the left or a down and to the right gesture. In another configuration, motion can be detected via the microphone as audio signals. Such a configuration can use less power than may be consumed by accelerometers.</p>\n",
      "<p id=\"p-0033\" num=\"0032\">In one such implementation an audio based motion detector can have multiple sub modules, such as a microphone with a built-in amplifier and high pass filter, a high-pass analog filter to filter out typical environmental noise, an amplifier, a low-pass filter, and an envelope detector.</p>\n",
      "<p id=\"p-0034\" num=\"0033\">The gesture component <b>634</b> can receive input from the sensors <b>630</b>. The gesture component <b>634</b> can identify user actions from the sensor input. For instance, assume that the user performs the touch action of instance one of <figref idref=\"DRAWINGS\">FIG. 5</figref>. In that case, pressure sensors <b>638</b>(<b>1</b>) and <b>638</b>(<b>3</b>) of <figref idref=\"DRAWINGS\">FIG. 6</figref> would detect pressure created by the lateral tendons and pressure sensor <b>638</b>(<b>2</b>) would not detect pressure. The gesture component can interpret the output of the three sensors <b>638</b>(<b>1</b>)-<b>638</b>(<b>3</b>) as a touch gesture. Now assume that the user performs the finger bend gesture of <figref idref=\"DRAWINGS\">FIG. 5</figref> instance two. In that case, each of sensors, <b>638</b>(<b>1</b>), <b>638</b>(<b>2</b>), and <b>638</b>(<b>3</b>) would detect pressure. The gesture component can interpret the output of the three sensors <b>638</b>(<b>1</b>)-<b>638</b>(<b>3</b>) as a non-touch finger bend gesture.</p>\n",
      "<p id=\"p-0035\" num=\"0034\">Other action detection (e.g., gesture detection) scenarios that involve identification of tapping, swiping, scrolling, and stroking for hand written text entry are described below.</p>\n",
      "<p id=\"p-0036\" num=\"0035\">The communication component <b>632</b> can allow the pressure sensitive smart ring <b>202</b> to communicate with various devices, such as the illustrated companion devices. The communication component can include a receiver and a transmitter and/or other radio frequency circuitry for communicating with various technologies, such as cellular, Wi-Fi (IEEE 802.xx), Bluetooth, etc.</p>\n",
      "<p id=\"p-0037\" num=\"0036\">Note that in some cases the gesture component <b>634</b> on the pressure sensitive ring <b>202</b> can be relatively robust and perform analysis on signals received from sensors <b>630</b> to identify a user action. The gesture component could then send an indication of the identified user action to a companion device (e.g., any of devices <b>304</b>, <b>306</b>, <b>402</b>, <b>502</b>, and/or <b>602</b>) that the pressure sensitive smart ring is operating in cooperation with. In other cases, the pressure sensitive smart ring could send the signals to the companion device. A gesture component (not shown) on the companion device could then analyze the sensor signals to identify the user action. In a similar scenario the pressure sensitive smart ring could send information to a remote resource, such as cloud based resources for processing.</p>\n",
      "<p id=\"p-0038\" num=\"0037\">The discussion below provides further details on specific implementations of the pressure sensitive smart ring <b>202</b>. For purposes of explanation, in this discussion smart phone <b>602</b> operates as a companion device to the pressure sensitive smart ring <b>202</b>. In this case, sensors <b>630</b> include force sensitive resistors, accelerometers, and an audio based sensor configured to detect motion of the user's finger on a surface. In this discussion, only a single pressure sensitive smart ring <b>202</b> is employed, but as noted above, the user could wear anywhere from one to ten pressure sensitive smart rings <b>202</b> (e.g., one on each finger including thumbs).</p>\n",
      "<p id=\"p-0039\" num=\"0038\">To conserve energy, the gesture detection component <b>634</b> can place the pressure sensitive smart ring <b>202</b> in an inactive sleep state to prevent accidental interpretation of day-to-day user activities as gestures. In this state, the ring's accelerometer can be in a low-power autonomous motion-detection state.</p>\n",
      "<p id=\"p-0040\" num=\"0039\">When the user is ready to enter gestures on an available surface, the pressure sensitive smart ring <b>202</b> can be brought into an active state by tapping the surface four times (or some other unique action). Once in the active state, the pressure sensitive smart ring <b>202</b> can enter a touch-detect active state by turning on the touch detection sensor. The 1st tap can help trigger the accelerometer motion detector, while the rest of the taps can be used to reduce accidental triggering of the active state. The gesture component <b>634</b> can collect raw accelerometer readings which can also be buffered during the touch-detect state.</p>\n",
      "<p id=\"p-0041\" num=\"0040\">When the user touches the surface to enter a gesture, the touch is detected by the pressure sensors, and the pressure sensitive smart ring <b>202</b> can enter motion-detect state. In the motion-detect state, the audio-based motion detector can be turned on to detect the motion of the finger along the surface. During this state, processed accelerometer components along a plane of the ring can be stored (e.g., yz plane). At the end of motion or the touch, the gesture detection component <b>634</b> can employ a classifier to the accelerometer data to identify the gesture.</p>\n",
      "<p id=\"p-0042\" num=\"0041\">This implementation of the gesture component <b>634</b> can implement the following four groups of gestures including, tap, swipe, scroll, and written text, which are summarized in Table 1. Of course other gestures are contemplated, especially when the user wears pressure sensitive smart rings on multiple fingers.</p>\n",
      "<p id=\"p-0043\" num=\"0042\">Tap. The tap gesture can satisfy a similar functionality to the typical tap gesture on a touch sensitive surface, or the left mouse click. Similar to touch surfaces and mice, multiple, closely spaced, tap actions can define multiple gestures. For instance, two double-taps can be used to transition between &#x201c;active&#x201d; and &#x201c;inactive&#x201d; modes as described above.</p>\n",
      "<p id=\"p-0044\" num=\"0043\">Swipe. The swipe gesture can be used with primitive touch interfaces for quickly scanning through multiple windows or a collection of items such as photos. This implementation of the pressure sensitive smart ring <b>202</b> can support four different swipe actions which include: swipe-up, swipe-down, swipe-left, and swipe-right.</p>\n",
      "<p id=\"p-0045\" num=\"0044\">\n",
      "<tables id=\"TABLE-US-00001\" num=\"00001\">\n",
      "<table frame=\"none\" colsep=\"0\" rowsep=\"0\">\n",
      "<tgroup align=\"left\" colsep=\"0\" rowsep=\"0\" cols=\"1\">\n",
      "<colspec colname=\"1\" colwidth=\"217pt\" align=\"center\"/>\n",
      "<thead>\n",
      "<row>\n",
      "<entry namest=\"1\" nameend=\"1\" rowsep=\"1\">TABLE 1</entry>\n",
      "</row>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<row>\n",
      "<entry namest=\"1\" nameend=\"1\" align=\"center\" rowsep=\"1\"/>\n",
      "</row>\n",
      "<row>\n",
      "<entry>Different gestures, including different modes, and</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry>number of classification primitives can be implemented</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry>on the pressure sensitive smart ring 202.</entry>\n",
      "</row>\n",
      "</tbody>\n",
      "</tgroup>\n",
      "<tgroup align=\"left\" colsep=\"0\" rowsep=\"0\" cols=\"3\">\n",
      "<colspec colname=\"1\" colwidth=\"49pt\" align=\"left\"/>\n",
      "<colspec colname=\"2\" colwidth=\"119pt\" align=\"left\"/>\n",
      "<colspec colname=\"3\" colwidth=\"49pt\" align=\"center\"/>\n",
      "<tbody valign=\"top\">\n",
      "<row>\n",
      "<entry>Gesture</entry>\n",
      "<entry>Modes</entry>\n",
      "<entry># primitives</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry namest=\"1\" nameend=\"3\" align=\"center\" rowsep=\"1\"/>\n",
      "</row>\n",
      "</tbody>\n",
      "</tgroup>\n",
      "<tgroup align=\"left\" colsep=\"0\" rowsep=\"0\" cols=\"3\">\n",
      "<colspec colname=\"1\" colwidth=\"49pt\" align=\"left\"/>\n",
      "<colspec colname=\"2\" colwidth=\"119pt\" align=\"left\"/>\n",
      "<colspec colname=\"3\" colwidth=\"49pt\" align=\"char\" char=\".\"/>\n",
      "<tbody valign=\"top\">\n",
      "<row>\n",
      "<entry>Tap</entry>\n",
      "<entry>down</entry>\n",
      "<entry>1</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry>Swipe</entry>\n",
      "<entry>up, down, left, right</entry>\n",
      "<entry>4</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry>Scroll</entry>\n",
      "<entry>up, down, left, right right-up, left-down</entry>\n",
      "<entry>6</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry>Written Text</entry>\n",
      "<entry>English characters</entry>\n",
      "<entry>12</entry>\n",
      "</row>\n",
      "<row>\n",
      "<entry namest=\"1\" nameend=\"3\" align=\"center\" rowsep=\"1\"/>\n",
      "</row>\n",
      "</tbody>\n",
      "</tgroup>\n",
      "</table>\n",
      "</tables>\n",
      "</p>\n",
      "<p id=\"p-0046\" num=\"0045\">Scroll. The scroll action can be similar to the touch surface or mouse-based scroll. The gesture component <b>634</b> can identify six scroll actions: scroll-left, scroll-right, scroll-up, scroll-down, scroll-right-up, and scroll-left-down.</p>\n",
      "<p id=\"p-0047\" num=\"0046\">Writing-based text entry. The pressure sensitive smart ring <b>202</b> can also implement a writing-based English text entry, where the user can simply write the characters on a surface using the index finger.</p>\n",
      "<p id=\"p-0048\" num=\"0047\">The gesture component <b>634</b> can treat each character as a combination of multiple primitive shapes called &#x201c;strokes&#x201d;. <figref idref=\"DRAWINGS\">FIG. 7</figref> shows examples of stroke gesture primitives <b>700</b>. In this example, 12 strokes are used for text entry in this implementation. The strokes can include directional and/or rotational movements. The gesture component can identify these strokes, and can also measure inter-stoke latencies which can help identify strokes belonging to a single character. The stroke identifiers and inter-stroke latencies can be used to identify the individual characters at a remote device.</p>\n",
      "<p id=\"h-0005\" num=\"0000\">Energy Harvesting</p>\n",
      "<p id=\"p-0049\" num=\"0048\">In this implementation, size and weight constraints limit the size of the battery used to power the pressure sensitive smart ring <b>202</b>. In one case, a 10 mAh battery capacity can be used to approximate a traditional jewelry type ring. This battery can fit in the crown or the finger band of the pressure sensitive smart ring <b>202</b>.</p>\n",
      "<p id=\"p-0050\" num=\"0049\">This relatively small 10 mAh battery capacity may cause the user to recharge the battery several times within a day, which would potentially be a large obstacle to the usability of the platform. To overcome this limitation, the pressure sensitive smart ring <b>202</b> can use the subcarrier based NFC energy harvesting approach to passively recharge the ring battery while the user is holding the smart phone <b>602</b> next to the ring.</p>\n",
      "<p id=\"p-0051\" num=\"0050\">To harvest energy from an NFC enabled antenna, the smart ring has a coil loop wound around the ring finger band. Winding the coil around the ring finger band can enable a large (and potentially maximum) loop size to achieve better energy harvesting.</p>\n",
      "<p id=\"h-0006\" num=\"0000\">Surface Detection</p>\n",
      "<p id=\"p-0052\" num=\"0051\">This implementation can use a combination of two techniques to detect the motion of the user's finger on a surface. As mentioned above, the pressure sensor can detect the finger touching a surface by sensing the pressure imparted by a lateral tendon of the finger; while an energy-efficient audio sensor can detect the movement of the finger on the surface by listening to the audio signal generated by the friction between the finger and the surface.</p>\n",
      "<p id=\"p-0053\" num=\"0052\">More specifically, the gesture component <b>634</b> can interpret the acoustic signals generated due to the friction when the finger moves across the surface to detect finger motion on the surface.</p>\n",
      "<p id=\"p-0054\" num=\"0053\">The amount of audio energy emitted from the finger/surface interaction is a function of the speed of finger motion and the physical properties of the surface.</p>\n",
      "<p id=\"p-0055\" num=\"0054\">Some implementations can offer enhanced surface detection using pressure and audio-based techniques. For instance, a combination of tendon pressure and audio based techniques can be analyzed to provide efficient and reliable surface detection due to the complementary characteristics of these techniques.</p>\n",
      "<p id=\"p-0056\" num=\"0055\">The tendon pressure-based technique can consume an order of magnitude less power than the audio-based solution, however, unlike the audio based solution, the pressure-based technique tends not to be able to identify finger motion directly. Accelerometers offer another solution, but at the potential cost of extra processing overhead and segmentation errors that can severely affect the system performance.</p>\n",
      "<p id=\"p-0057\" num=\"0056\">The audio-solution can detect both motion and touch during motion. However, the audio-based solution can be affected by ambient audio noise-induced errors. Band-pass filtering can remove a significant portion of these errors. The touch detector can prevent the accidental triggering of motion sensing due to errors that are not filtered. The touch detector can also prevent cascading failures by touch-based gating of the gesture detection in the presence of noise.</p>\n",
      "<p id=\"h-0007\" num=\"0000\">Gesture Classification</p>\n",
      "<p id=\"p-0058\" num=\"0057\">In some implementations the gesture component <b>634</b> can utilize classifiers for identifying the gesture primitives. For instance, gesture primitives can be categorized based on starting dynamics, real-timeliness, and context dependency of interpretation.</p>\n",
      "<p id=\"p-0059\" num=\"0058\">Hard landing gestures start with the user's finger landing on the surface at a relatively high velocity. Both taps and swipes can be hard landing gestures. Soft landing gestures can start with the finger meeting the surface at a low velocity. Both scroll gestures and strokes for text entry can be soft landing gestures.</p>\n",
      "<p id=\"p-0060\" num=\"0059\">The scroll gestures can entail real-time identification, since the user tends to desire continuous feedback on the current scroll position. Due to short interaction time, both tap and swipe gestures can be identified in non-real-time after the gesture has been completed. The strokes for text entry can also be identified in non-real-time, at the end of each stroke to improve classification accuracy. This is acceptable since the high-level symbols, such as characters, can only be interpreted after collecting all strokes that make up the character, due to lack of absolute position.</p>\n",
      "<p id=\"p-0061\" num=\"0060\">Context free gestures are gestures that can be interpreted on the pressure sensitive smart ring <b>202</b> without the knowledge of the user interface (UI) element the user is interacting with. Both tapping and swiping gestures belong to this category.</p>\n",
      "<p id=\"p-0062\" num=\"0061\">Context dependent gestures can utilize knowledge of the current UI element type for correct interpretation by the pressure sensitive smart ring <b>202</b>. Some of the stroke and scroll gestures that look identical can be interpreted differently due to different real-time needs. To enable proper interpretation of these, the gesture component <b>634</b> can operate on the presumption that the remote device informs the pressure sensitive smart ring <b>202</b> when the user starts and stops interacting with a text entry area.</p>\n",
      "<p id=\"h-0008\" num=\"0000\">Resolving Angular Ambiguity of Accelerometer Data</p>\n",
      "<p id=\"p-0063\" num=\"0062\">The pressure sensitive smart ring <b>202</b>'s gesture component <b>634</b> can use the accelerometer data to identify different gestures on a surface. When gestures are performed on a surface, the signature of the gesture tends to be captured in the acceleration components that are parallel to the surface of interaction. Since the pressure sensitive smart ring <b>202</b>, when worn on the finger, does not stay parallel to the interaction surface, and since individual users' frames of reference will differ from one another, the gesture component can convert the (x,y,z) components of the accelerometer to the (x,y,z) components with respect to the interacting plane. Some implementations can assume a horizontal plane of interaction, which is true for most of the interaction surfaces available in the environment. Other implementations can handle the interaction on an arbitrarily inclined plane.</p>\n",
      "<p id=\"p-0064\" num=\"0063\">For computing the components along the interacting plane, the gesture component <b>634</b> can use the gravity acceleration vector just prior to movement of the finger to determine the inclination of the finger to the plane, since this angle can vary across users and instances.</p>\n",
      "<p id=\"p-0065\" num=\"0064\">To perform this normalization, the gesture component <b>634</b> can compute two angles: pitch (&#x3b8;) and roll (&#x3d5;). These angles can be computed according to the following equations:</p>\n",
      "<p id=\"p-0066\" num=\"0065\">\n",
      "<maths id=\"MATH-US-00001\" num=\"00001\">\n",
      "<math overflow=\"scroll\">\n",
      "<mtable>\n",
      "  <mtr>\n",
      "    <mtd>\n",
      "      <mrow>\n",
      "        <msub>\n",
      "          <mi>&#x3b8;</mi>\n",
      "          <mi>xyz</mi>\n",
      "        </msub>\n",
      "        <mo>=</mo>\n",
      "        <mrow>\n",
      "          <msup>\n",
      "            <mi>tan</mi>\n",
      "            <mrow>\n",
      "              <mo>-</mo>\n",
      "              <mn>1</mn>\n",
      "            </mrow>\n",
      "          </msup>\n",
      "          <mo>&#x2061;</mo>\n",
      "          <mrow>\n",
      "            <mo>(</mo>\n",
      "            <mfrac>\n",
      "              <mrow>\n",
      "                <mo>-</mo>\n",
      "                <msub>\n",
      "                  <mi>G</mi>\n",
      "                  <mi>px</mi>\n",
      "                </msub>\n",
      "              </mrow>\n",
      "              <msub>\n",
      "                <mi>G</mi>\n",
      "                <mi>pz</mi>\n",
      "              </msub>\n",
      "            </mfrac>\n",
      "            <mo>)</mo>\n",
      "          </mrow>\n",
      "        </mrow>\n",
      "      </mrow>\n",
      "    </mtd>\n",
      "    <mtd>\n",
      "      <mrow>\n",
      "        <mo>(</mo>\n",
      "        <mn>1</mn>\n",
      "        <mo>)</mo>\n",
      "      </mrow>\n",
      "    </mtd>\n",
      "  </mtr>\n",
      "  <mtr>\n",
      "    <mtd>\n",
      "      <mrow>\n",
      "        <msub>\n",
      "          <mi>&#x3d5;</mi>\n",
      "          <mi>xyz</mi>\n",
      "        </msub>\n",
      "        <mo>=</mo>\n",
      "        <mrow>\n",
      "          <msup>\n",
      "            <mi>tan</mi>\n",
      "            <mrow>\n",
      "              <mo>-</mo>\n",
      "              <mn>1</mn>\n",
      "            </mrow>\n",
      "          </msup>\n",
      "          <mo>&#x2061;</mo>\n",
      "          <mrow>\n",
      "            <mo>(</mo>\n",
      "            <mfrac>\n",
      "              <msub>\n",
      "                <mi>G</mi>\n",
      "                <mi>py</mi>\n",
      "              </msub>\n",
      "              <msqrt>\n",
      "                <mrow>\n",
      "                  <msubsup>\n",
      "                    <mi>G</mi>\n",
      "                    <mi>px</mi>\n",
      "                    <mn>2</mn>\n",
      "                  </msubsup>\n",
      "                  <mo>+</mo>\n",
      "                  <msubsup>\n",
      "                    <mi>G</mi>\n",
      "                    <mi>pz</mi>\n",
      "                    <mn>2</mn>\n",
      "                  </msubsup>\n",
      "                </mrow>\n",
      "              </msqrt>\n",
      "            </mfrac>\n",
      "            <mo>)</mo>\n",
      "          </mrow>\n",
      "        </mrow>\n",
      "      </mrow>\n",
      "    </mtd>\n",
      "    <mtd>\n",
      "      <mrow>\n",
      "        <mo>(</mo>\n",
      "        <mn>2</mn>\n",
      "        <mo>)</mo>\n",
      "      </mrow>\n",
      "    </mtd>\n",
      "  </mtr>\n",
      "</mtable>\n",
      "</math>\n",
      "</maths>\n",
      "</p>\n",
      "<p id=\"p-0067\" num=\"0066\">After computing these angles while the finger is stationary, they can be applied to subsequent accelerometer samples to compensate for finger orientation while the finger is moving:\n",
      "<br/>\n",
      "<?in-line-formulae description=\"In-line Formulae\" end=\"lead\"?><i>x</i><sub>normal</sub><i>=&#x2212;x</i>&#xb7;cos(&#x2212;&#x3d5;)+<i>z</i>&#xb7;sin(&#x2212;&#x3d5;)&#x2003;&#x2003;(3)<?in-line-formulae description=\"In-line Formulae\" end=\"tail\"?>\n",
      "<br/>\n",
      "<?in-line-formulae description=\"In-line Formulae\" end=\"lead\"?><i>y</i><sub>normal</sub><i>=y</i>&#xb7;cos(&#x3b8;)&#x2212;<i>z</i>&#xb7;sin(&#x3b8;)&#x2003;&#x2003;(4)<?in-line-formulae description=\"In-line Formulae\" end=\"tail\"?>\n",
      "</p>\n",
      "<p id=\"p-0068\" num=\"0067\">There are two limitations to correcting for the finger angle in this way. First, some implementations can operate on the assumption that these angles do not change during a gesture&#x2014;if this assumption is violated, the gravity vector may pollute the x and y components, and a fraction of the x and y accelerations will be falsely attributed to the z axis. Second, some implementations do not correct for a third orientation angle, yaw (&#x3c8;), if gyros are not utilized (gravity vector provides no information as to how the finger twists in a plane perpendicular to gravity). Thus, these implementations can leverage the assumption that the user's finger motion will be perpendicular to their body and the impact of &#x3c8; is negligible. If this assumption is violated, the x and y acceleration components may not be properly separated. While worth noting, neither of these limitations tends to have a significant impact on classification accuracy.</p>\n",
      "<p id=\"h-0009\" num=\"0000\">Gesture Classification Overview</p>\n",
      "<p id=\"p-0069\" num=\"0068\">Some implementations of the gesture component <b>634</b> can use a two-level classification scheme for gesture classification. When the pressure sensors indicate a touch event, the top-level classifier, called the landing classifier, can be invoked to classify the event as either a soft landing event or a hard landing event. The gesture component <b>634</b> can evaluate the output of the landing classifier and the UI context reported by the companion device (e.g., the device the user is engaging). The gesture component <b>634</b> can then invoke one of the low level classifiers&#x2014;swipe-tap, stroke, or scroll.</p>\n",
      "<p id=\"p-0070\" num=\"0069\">The gesture component <b>634</b> can also invoke the swipe-tap classifier to handle a hard landing. This classifier can use the surface touch duration&#x2014;determined by the length of the audio envelope, and the accelerometer samples to classify the event as either a tap gesture or one of the four swipe gestures.</p>\n",
      "<p id=\"p-0071\" num=\"0070\">For a soft landing, if the context reports text input, the gesture component <b>634</b> can invoke the stroke classifier. Since there can be multiple consecutive strokes during a single touch, for example when writing L character, accelerometer data collected after the soft landing can be segmented based on the audio envelope. These segmented data can be fed to the stroke classifier to classify the stroke to one of the 12 possible strokes. This process can continue until the finger leaves the surface.</p>\n",
      "<p id=\"p-0072\" num=\"0071\">For a soft landing with a non-text input context, the gesture component <b>634</b> can invoke the scroll classifier. The scroll classifier can first detect a short &#x2018;nudge&#x2019; at the start of the scroll based on the audio envelope, and can classify the data collected between the touch event and the end of the nudge to determine the type of scroll event. After this classification stage, the smart ring periodically can transmit &#x2018;in-scroll&#x2019; messages to the companion device to provide real-time information on the continued scroll event until the finger stops moving and leaves the surface.</p>\n",
      "<p id=\"p-0073\" num=\"0072\"><figref idref=\"DRAWINGS\">FIG. 8</figref> shows a state diagram <b>800</b> of how different classification stages can be invoked in some implementations. The rest of this section describes these classification stages in more detail.</p>\n",
      "<p id=\"h-0010\" num=\"0000\">Landing Classifier</p>\n",
      "<p id=\"p-0074\" num=\"0073\">While the finger is moving on a surface, negligible activity on an accelerometer's z-axis is expected. However, when the finger initially lands on the surface, the finger can abruptly stop, causing large magnitude, short-lived spikes induced by the finger's sudden deceleration. The gesture component <b>634</b> (<figref idref=\"DRAWINGS\">FIG. 6</figref>) can classify hard landings versus soft landings by exploiting this activity on the accelerometer z-axis at the beginning of a gesture entry. When a surface is initially detected at <b>802</b>, n samples can be evaluated surrounding the start of motion. These n samples may be used as the input to a heuristic, threshold-based classification or as the input to an SVM classifier. The intuition behind the efficacy of each of these approaches is the existence of large, observable deltas in z-axis acceleration. To summarize, the z-axis magnitude can be compared to a threshold. A magnitude below the threshold can indicate a soft landing <b>804</b>. A magnitude that is equal to or above the threshold can indicate a hard landing <b>806</b>.</p>\n",
      "<p id=\"h-0011\" num=\"0000\">Swipe-Tap Classifier</p>\n",
      "<p id=\"p-0075\" num=\"0074\">The swipe-tap classifier can be invoked after detecting a hard landing <b>806</b>. A duration envelope of the contact of the finger across the surface can be compared to a duration threshold. A duration envelope that is less than the duration threshold can indicate a tap event <b>808</b>. A duration that is longer than the duration threshold can indicate a swipe event <b>810</b>.</p>\n",
      "<p id=\"p-0076\" num=\"0075\">A tap gesture can be identified solely from the envelope information, while identification of a swipe can entail further classification.</p>\n",
      "<p id=\"h-0012\" num=\"0000\">Stroke Classifier</p>\n",
      "<p id=\"p-0077\" num=\"0076\">Returning to soft landing <b>804</b>, the soft landing can be evaluated to distinguish a scroll <b>812</b> from a stroke <b>814</b>. An SVM classifier can be utilized to classify strokes. The SVM classifier can use the x, y, and z axis accelerometer readings as the feature vector. Since the stroke duration can vary at different instances as well as across users, a sample, such as 100 points can be linearly interpolated across each x and y axis sample for a given gesture. A fixed number of averages can be computed across these interpolated points for each axis. This set of averages can then be passed to the SVM classifier.</p>\n",
      "<p id=\"h-0013\" num=\"0000\">Scroll Classifier</p>\n",
      "<p id=\"p-0078\" num=\"0077\">Scroll classification can happen after a stroke is detected based on the context of the remote user interface (e.g., the companion device that the user is engaging). A short gesture, called a &#x2018;nudge&#x2019;, can be detected and classified using the SVM classifier to determine the start of one of the six possible scroll gestures. Some implementations can utilize a relatively small number of (such as six) different scroll gestures to ease classification of the scroll action with only a small number of samples. After the user performs the nudge, the length of the envelope can provide real-time information to the remote device on the progress of the scroll action.</p>\n",
      "<p id=\"h-0014\" num=\"0000\">Operating Modes</p>\n",
      "<p id=\"p-0079\" num=\"0078\">When the pressure sensitive smart ring <b>202</b> is in the active mode (touch-detect, or touch-process), the activity of the platform can be driven by the accelerometer. The accelerometer can autonomously collect samples at &#x2243;400 Hz (for example) and can interrupt the microcontroller when a new sample is available.</p>\n",
      "<p id=\"p-0080\" num=\"0079\">During touch-detect, the sampled data can be buffered for landing type estimation, the microcontroller interrupt service routine (ISR) also can check the status of the touch detector.</p>\n",
      "<p id=\"p-0081\" num=\"0080\">If touch is active, the pressure sensitive smart ring <b>202</b> can transition to touch-process mode. In this mode, the audio-based motion detector output can be sampled at &#x2243;100 Hz with processor ADC (at every 4th ISR). Once motion is detected&#x2014;determined by the change of audio envelope by a preset threshold&#x2014;the pressure sensitive smart ring <b>202</b> can start accumulating coordinate-aligned accelerometer data. At the end of the motion, the appropriate classifier can be invoked, and the results can be transmitted over the radio (e.g., communication component <b>632</b>), such as by using a best effort transmission scheme.</p>\n",
      "<p id=\"h-0015\" num=\"0000\">SVM Classifier Implementation</p>\n",
      "<p id=\"p-0082\" num=\"0081\">As introduced above, an SVM classifier can be employed for gesture classification. The SVM classifier can be a multi-class linear-kernel SVM classifier. The SVM classifier can use pair-wise classification, entailing n(n&#x2212;1)/pair-wise classifiers to classify n classes.</p>\n",
      "<p id=\"p-0083\" num=\"0082\">Some implementations can use four features for each x and y axis, resulting in eight SVM features. Each (F(i)<sub>x</sub>,F(i)<sub>y</sub>) feature tuple can be calculated by first breaking all the (x,y) acceleration data in to four buckets, and then averaging the data in each bucket. The x and y acceleration component of each data sample can be computed immediately after reading (x,y,z) acceleration data sample from the accelerometer.</p>\n",
      "<p id=\"p-0084\" num=\"0083\">Due to limited RAM size, instead of buffering data at 400 Hz until the end of a gesture, some implementations can employ running averages of each n samples of data to be calculated. Value n can be selected such that there are at most 60 computed averages for the worst case duration of each gesture class. Once the gesture ends, these pre-computed averages can be broken into four equal-size buckets to compute the four feature tuples.</p>\n",
      "<p id=\"h-0016\" num=\"0000\">NFC Energy Harvesting</p>\n",
      "<p id=\"p-0085\" num=\"0084\">As mentioned above, wireless charging can be achieved via magnetic fields generated by a companion device, such as smart phone <b>602</b>. Some implementations can be configured so that the charging occurs efficiently (potentially maximally) when the user holds the smart phone in a natural manner with the ring bearing hand.</p>\n",
      "<p id=\"p-0086\" num=\"0085\">In summary, at least some of the present implementations can offer a low-power wearable smart ring that can enable users to enter gestures by interacting on arbitrary surfaces. The smart ring can use energy efficient finger-tendon based touch detection and audio-based motion detection to capture user interaction instances. A light-weight mufti-classifier solution accurately classifies different gesture primitives. In one case, using a 10 mAh battery powered by energy harvested from an NFC-enabled smart phone, the ring can support more than 10 hours of active user interactions.</p>\n",
      "<heading id=\"h-0017\" level=\"1\">EXAMPLE METHODS</heading>\n",
      "<p id=\"p-0087\" num=\"0086\"><figref idref=\"DRAWINGS\">FIG. 9</figref> illustrates a flowchart of a method or technique <b>900</b> that is consistent with at least some implementations of the present concepts.</p>\n",
      "<p id=\"p-0088\" num=\"0087\">At block <b>902</b>, the method can obtain signals reflecting pressure of a tendon of a user's finger on a ring positioned on the finger.</p>\n",
      "<p id=\"p-0089\" num=\"0088\">At block <b>904</b>, the method can interpret the signals to identify an action performed by the finger.</p>\n",
      "<p id=\"p-0090\" num=\"0089\">In some cases, the method can be performed on the ring by a processor or microcontroller. In other cases, the signals can be sent from the ring to another device, such as a companion device that is proximate to the ring and is working cooperatively with the ring. The companion device can then perform the interpreting. Some implementations can involve a single user wearing multiple rings. In such a case, each ring can communicate its signals to the companion device (e.g., with a different ring identifier with the signals). The companion device can then interpret actions relating to a single finger or multiple fingers (e.g., multi-finger gestures). For instance, the user may have waved a single finger to invoke a specific user command or the user could have waved all the fingers of the hand to invoke a different user command. In some cases, the smart ring may contain other sensors that sense other parameters. Signals from the other sensors can be interpreted in combination with signals from the pressure sensors to identify the user action. In still other cases, sensors on other devices may provide signals that can be utilized in combination with the sensed signals to identify the user action. Examples of such scenarios are illustrated relative to <figref idref=\"DRAWINGS\">FIGS. 3-5</figref> where the digital display <b>304</b>, the depth sensor <b>306</b>, the smart glasses <b>402</b>, and/or the smart watch <b>502</b> may sense the user and provide data that is useful in combination with the pressure data. Also, in some cases, such as a digital whiteboard scenario, multiple users may be performing actions and each user may be wearing one or more smart rings.</p>\n",
      "<p id=\"p-0091\" num=\"0090\">The order in which the above methods are described is not intended to be construed as a limitation, and any number of the described blocks can be combined in any order to implement the method, or an alternate method. Furthermore, the method can be implemented in any suitable hardware, software, firmware, or combination thereof, such that a computing device can implement the method (e.g., computer-implemented method). In one case, the method is stored on a computer-readable storage media as a set of instructions such that execution by a processor of a computing device causes the computing device to perform the method.</p>\n",
      "<heading id=\"h-0018\" level=\"1\">CONCLUSION</heading>\n",
      "<p id=\"p-0092\" num=\"0091\">In summary, the present implementations can derive useful information about user actions from pressure sensors on a smart ring worn on a user's finger.</p>\n",
      "<p id=\"p-0093\" num=\"0092\">The described methods or processes can be performed by the systems and/or devices described above, and/or by other devices and/or systems. The order in which the methods are described is not intended to be construed as a limitation, and any number of the described acts can be combined in any order to implement the method, or an alternate method. Furthermore, the method can be implemented in any suitable hardware, software, firmware, or combination thereof, such that a device can implement the method. In one case, the method is stored on computer-readable storage media as a set of instructions such that execution by a processor of a computing device causes the computing device to perform the method.</p>\n",
      "<p id=\"p-0094\" num=\"0093\">Although techniques, methods, devices, systems, etc., pertaining to detecting user actions are described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as exemplary forms of implementing the claimed methods, devices, systems, etc.</p>\n",
      "<?DETDESC description=\"Detailed Description\" end=\"tail\"?>\n",
      "</description>\n",
      "<us-math idrefs=\"MATH-US-00001\" nb-file=\"US10359846-20190723-M00001.NB\">\n",
      "<img id=\"EMI-M00001\" he=\"18.71mm\" wi=\"76.20mm\" file=\"US10359846-20190723-M00001.TIF\" alt=\"embedded image \" img-content=\"math\" img-format=\"tif\"/>\n",
      "</us-math>\n",
      "<us-claim-statement>The invention claimed is:</us-claim-statement>\n",
      "<claims id=\"claims\">\n",
      "<claim id=\"CLM-00001\" num=\"00001\">\n",
      "<claim-text>1. A wearable device comprising:\n",
      "<claim-text>at least one sensor configured to output a sensor signal reflecting movement of the wearable device; and</claim-text>\n",
      "<claim-text>at least one processor or hardware logic circuit configured to:\n",
      "<claim-text>receive a report from a remote device with which the wearable device is capable of interacting;</claim-text>\n",
      "<claim-text>determine, based at least on the report received from the remote device, a current user interface context of the remote device; and</claim-text>\n",
      "<claim-text>selectively interpret the sensor signal based at least on the current user interface context of the remote device to identify a particular gesture being performed with the wearable device.</claim-text>\n",
      "</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00002\" num=\"00002\">\n",
      "<claim-text>2. The wearable device of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>determine that the report indicates that the current user interface context of the remote device is a text entry context; and</claim-text>\n",
      "<claim-text>based at least on determining that the report indicates that the current user interface context of the remote device is the text entry context, identify the particular gesture as a writing stroke.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00003\" num=\"00003\">\n",
      "<claim-text>3. The wearable device of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>determine that the report indicates that the current user interface context of the remote device is not a text entry context; and</claim-text>\n",
      "<claim-text>based at least on determining that the report indicates that the current user interface context of the remote device is not a text entry context, identify the particular gesture as a scroll event.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00004\" num=\"00004\">\n",
      "<claim-text>4. The wearable device of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, the at least one sensor being an accelerometer.</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00005\" num=\"00005\">\n",
      "<claim-text>5. The wearable device of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref>, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>when an accelerometer signal received from the accelerometer is indicative of a landing on another surface, compare a magnitude of the accelerometer signal to a threshold;</claim-text>\n",
      "<claim-text>in instances when the magnitude of the accelerometer signal exceeds the threshold, identify the particular gesture as a hard-landing gesture; and</claim-text>\n",
      "<claim-text>in other instances when the magnitude of the accelerometer signal does not exceed the threshold, identify the particular gesture as a soft-landing gesture.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00006\" num=\"00006\">\n",
      "<claim-text>6. The wearable device of <claim-ref idref=\"CLM-00005\">claim 5</claim-ref>, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>compare a duration of the hard-landing gesture to a duration threshold;</claim-text>\n",
      "<claim-text>when the duration of the hard-landing gesture is less than the duration threshold, interpret the hard-landing gesture as a tap gesture; and</claim-text>\n",
      "<claim-text>when the duration of the hard-landing gesture is greater than the duration threshold, interpret the hard-landing gesture as a swipe gesture.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00007\" num=\"00007\">\n",
      "<claim-text>7. The wearable device of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, the remote device being a local companion device, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>transmit an indication of the particular gesture to the local companion device.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00008\" num=\"00008\">\n",
      "<claim-text>8. The wearable device of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the at least one processor or hardware logic circuit is further configured to:\n",
      "<claim-text>transmit the indication of the particular gesture to the local companion device using short-range wireless communication.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00009\" num=\"00009\">\n",
      "<claim-text>9. A method comprising:\n",
      "<claim-text>obtaining a sensor signal reflecting movement of a wearable device;</claim-text>\n",
      "<claim-text>receiving a report from a remote device with which the wearable device is capable of interacting;</claim-text>\n",
      "<claim-text>determining, based at least on the report received from the remote device, a current user interface context of the remote device; and</claim-text>\n",
      "<claim-text>selectively interpreting the sensor signal based at least on the current user interface context of the remote device to identify a particular gesture being performed with the wearable device.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00010\" num=\"00010\">\n",
      "<claim-text>10. The method of <claim-ref idref=\"CLM-00009\">claim 9</claim-ref>, further comprising:\n",
      "<claim-text>transmitting an indication of the particular gesture to the remote device.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00011\" num=\"00011\">\n",
      "<claim-text>11. The method of <claim-ref idref=\"CLM-00009\">claim 9</claim-ref>, performed entirely by the wearable device.</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00012\" num=\"00012\">\n",
      "<claim-text>12. The method of <claim-ref idref=\"CLM-00009\">claim 9</claim-ref>, further comprising:\n",
      "<claim-text>when the current user interface context is a text entry context, interpreting the particular gesture as a writing stroke.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00013\" num=\"00013\">\n",
      "<claim-text>13. The method of <claim-ref idref=\"CLM-00012\">claim 12</claim-ref>, further comprising:\n",
      "<claim-text>identifying a particular character entered at least in part by the writing stroke; and</claim-text>\n",
      "<claim-text>entering the particular character to the remote device.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00014\" num=\"00014\">\n",
      "<claim-text>14. The method of <claim-ref idref=\"CLM-00013\">claim 13</claim-ref>, further comprising:\n",
      "<claim-text>when the current user interface context is not a text entry context, interpreting the particular gesture as a scroll event.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00015\" num=\"00015\">\n",
      "<claim-text>15. The method of <claim-ref idref=\"CLM-00014\">claim 14</claim-ref>, further comprising:\n",
      "<claim-text>identifying a particular direction of the scroll event; and</claim-text>\n",
      "<claim-text>causing the remote device to perform a scrolling action in the particular direction.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00016\" num=\"00016\">\n",
      "<claim-text>16. A computer-readable storage medium storing instructions which, when executed by a processor, cause a processor to perform acts comprising:\n",
      "<claim-text>obtaining a sensor signal reflecting movement of a wearable device;</claim-text>\n",
      "<claim-text>receiving a report from a remote device with which the wearable device is capable of interacting;</claim-text>\n",
      "<claim-text>determining, based at least on the report received from the remote device, a current user interface context of the remote device; and</claim-text>\n",
      "<claim-text>selectively interpreting the sensor signal based at least on the current user interface context of the remote device to identify a particular gesture being performed with the wearable device.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00017\" num=\"00017\">\n",
      "<claim-text>17. The computer-readable storage medium of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, the acts further comprising:\n",
      "<claim-text>transmitting an indication of the particular gesture to the remote device using short-range wireless communication.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00018\" num=\"00018\">\n",
      "<claim-text>18. The computer-readable storage medium of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, the acts further comprising:\n",
      "<claim-text>processing the sensor signal using a trained classifier to identify the particular gesture.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00019\" num=\"00019\">\n",
      "<claim-text>19. The computer-readable storage medium of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, the sensor signal comprising an accelerometer signal, the trained classifier comprising a support vector machine configured to classify the accelerometer signal as writing strokes or scroll gestures.</claim-text>\n",
      "</claim>\n",
      "<claim id=\"CLM-00020\" num=\"00020\">\n",
      "<claim-text>20. The computer-readable storage medium of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, the acts further comprising:\n",
      "<claim-text>interpreting the particular gesture as a writing stroke when the report indicates that the current user interface context of the remote device is a text entry context; and</claim-text>\n",
      "<claim-text>interpreting the particular gesture as a scroll event when the report indicates that the current user interface context of the remote device is not a text entry context.</claim-text>\n",
      "</claim-text>\n",
      "</claim>\n",
      "</claims>\n",
      "</us-patent-grant>\n"
     ]
    }
   ],
   "source": [
    "print(patents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse group17.txt\n",
    "\n",
    "The first task was to extract some data. This was done as follows:\n",
    "\n",
    "1. Grant ID- a unique ID for a patent grant made of alphanumeric characters. \n",
    "In order to do this, we used regular expressions, the re findall function. We found that this ID was located between 'file=\"' and '-' on numerous instances in one patent record. We therefore went one patent at a time and used the all() function to check if every occurance is the same, and if it was, then that ID is added to a list 'grant_id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_id=[]\n",
    "for item in patents:\n",
    "    gid=re.findall(r'file=\"([A-Z]+[0-9]+)-', item)\n",
    "    if all(x == gid[0] for x in gid): #checks to see if all items are the same, if yes then the item is added to the list\n",
    "        grant_id.append(gid[0])   \n",
    "    else:\n",
    "        print(\"ERROR!\")\n",
    "len(grant_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Patent title- a title given by the inventor. We noticed that the patent title occured only once in each patent instance and therefore used a regular expression and the re findall function to go through the entire text file and extract the title of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_title=re.findall(r'\\>(.*?)\\</invention-title>', text)\n",
    "len(patent_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Patent kind- a category to which the patent grant belongs. In order to do this, we had to derive the meaning of each Id used. \n",
    "\n",
    "    - B1: Utility Patent Grant (no published application) issued on or after January 2, 2001.\n",
    "    - B2: Utility Patent Grant (with a published application) issued on or after January 2, 2001.\n",
    "    - S1: Design Patent\n",
    "    - E1: Reissue Patent\n",
    "    - P2: Plant Patent Grant (no published application) issued on or after January 2, 2001\n",
    "    - P3: Plant Patent Grant (with a published application) issued on or after January 2, 2001\n",
    "\n",
    "We first noticed that each xml block had numerous \"kind\" elements. We had to extract the appropriate portion using regular expressions. We then got the kind id and checked each and appended the appropriate string to the list \"kind\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_kind=[]\n",
    "for item in patents:\n",
    "    line=re.findall(r'<us-bibliographic-data-grant>(.*?)</document-id>', item, flags=16)\n",
    "    for item1 in line:\n",
    "        kind=re.findall(r'<kind>(.*?)</kind>', item1)\n",
    "        for item2 in kind:\n",
    "            if item2==\"B1\":\n",
    "                k=\"Utility Patent Grant (no published application) issued on or after January 2, 2001.\"\n",
    "            elif item2==\"B2\":\n",
    "                k=\"Utility Patent Grant (with a published application) issued on or after January 2, 2001.\"\n",
    "            elif item2==\"S1\":\n",
    "                k=\"Design Patent\"\n",
    "            elif item2==\"E1\":\n",
    "                k=\"Reissue Patent\"\n",
    "            elif item2==\"P2\":\n",
    "                k=\"Plant Patent Grant (no published application) issued on or after January 2, 2001\"\n",
    "            elif item2==\"P3\":\n",
    "                k=\"Plant Patent Grant (with a published application) issued on or after January 2, 2001\"           \n",
    "    patent_kind.append(k)\n",
    "len(patent_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Number of claims- integer denoting the number of claims for a given grant. We noticed that the number of claims occured only once in each patent instance and therefore used a regular expression and the re findall function to go through the entire text file and extract the integer for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_claims=re.findall(r'\\>(.*?)\\</number-of-claims>', text)\n",
    "len(number_of_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Citations examiner count- integer that denotes the number of citations made by an examiner. We counted the number of occurances of the text \"cited by examiner\" in each pantent entry and stored the number in a list \"citations_examiner_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_examiner_count=[]\n",
    "for item in patents:\n",
    "    citations_examiner_count.append(len(re.findall(r'cited by examiner', item)))\n",
    "len(citations_examiner_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Citations applicant count- integer that denotes the number of citations made by the applicant of the grant. We counted the number of occurances of the text \"cited by applicant\" in each pantent entry and stored the number in a list \"citations_applicant_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_applicant_count=[]\n",
    "for item in patents:\n",
    "    citations_applicant_count.append(len(re.findall(r'cited by applicant', item)))\n",
    "len(citations_applicant_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Inventors- a list of the patent inventors. We noticed that the the names of the inventors were split as first name and last name. We therefore extracted every first name and every last name in each patent and joined the two lists in order and created one list per patent. We then joined each of these lists together so that the each element in the overall list is a string of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventors=[]\n",
    "for item in patents:\n",
    "    inventor=[]\n",
    "    reg = r'<inventors>.*?</inventors>' \n",
    "    text=re.findall(reg, item, flags=16)\n",
    "    if len(text)==0:\n",
    "        inventor=[\"NA\"]\n",
    "    else:\n",
    "        for item in text:\n",
    "            Lname=re.findall(r'<last-name>(.*?)</last-name>', item)\n",
    "            Fname=re.findall(r'<first-name>(.*?)</first-name>', item)\n",
    "            for i in range(len(Fname)):\n",
    "                inventor.append(Fname[i]+\" \"+Lname[i])\n",
    "    inventors.append(inventor)\n",
    "\n",
    "for i in range(len(inventors)):\n",
    "        inventors[i] = \"[\"+\",\".join(inventors[i])+\"]\"\n",
    "len(inventors)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Claims text- list of claims text for the various patent claims. We used regular expressions and the re library's findall and sub function to find the relevent data and clean it. The claims text for the various patents are in the list \"claims_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_text=[]\n",
    "for item in patents:\n",
    "    claims=[]\n",
    "    reg=r'<claim-text>.*?</claim>'\n",
    "    te=re.findall(reg, item, flags=16)\n",
    "    if len(te)==0:\n",
    "        claims1=\"[NA]\"\n",
    "    else:\n",
    "        for item in te:\n",
    "            item=re.sub(r'<.+?>', '', item)\n",
    "            item=re.sub(r'\\n', '', item)\n",
    "            claims.append(item.strip())\n",
    "            claims1=\"[\"+\",\".join(claims)+\"]\"\n",
    "    claims_text.append(claims1)       \n",
    "len(claims_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Abstract- the patent abstract text. This is extracted in a similar manner to thats of the claims text- using the re library and regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract=[]\n",
    "for item in patents:\n",
    "    reg=r'<abstract id=\"abstract\">.*?</abstract>'\n",
    "    t=re.findall(reg, item, flags=16)\n",
    "    if len(t)==0:\n",
    "        abst=\"NA\"\n",
    "    else:\n",
    "        for item1 in t:\n",
    "            t2=re.findall(r'>(.*?)</p>', item1)\n",
    "            for item2 in t2:\n",
    "                item2=re.sub(r'<.+?>', '', item2)\n",
    "                item2=re.sub(r'\\n', '', item2)\n",
    "                abst=item2\n",
    "    abstract.append(abst)\n",
    "len(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally combined the various lists to create a pandas dataframe containing all the extracted data in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grant_id</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>kind</th>\n",
       "      <th>number_of_claims</th>\n",
       "      <th>inventors</th>\n",
       "      <th>citations_applicant_count</th>\n",
       "      <th>citations_examiner_count</th>\n",
       "      <th>claims_text</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US10359846</td>\n",
       "      <td>Wearable device gesture detection</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Nissanka Arachchige Bodhi Priyantha,Jie Liu]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1. A wearable device comprising:at least one ...</td>\n",
       "      <td>The description relates to smart rings. One ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10360147</td>\n",
       "      <td>Data storage layout</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Kyle B. Wheeler,Timothy P. Finkbeiner]</td>\n",
       "      <td>296</td>\n",
       "      <td>12</td>\n",
       "      <td>[1. A system for storing data elements compris...</td>\n",
       "      <td>Examples of the present disclosure provide app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US10360793</td>\n",
       "      <td>Preventing vehicle accident caused by intentio...</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Eliseba Costantini,Alice Guidotti,Daniele Mor...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. A method for detecting and managing a vehi...</td>\n",
       "      <td>A method, computer system, and a computer prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US10358535</td>\n",
       "      <td>Thermal interface material</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Matthew Collins Weisenberger,John Davis Cradd...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>[1. A thermal interface material, comprising:a...</td>\n",
       "      <td>A flexible sheet of aligned carbon nanotubes i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10361019</td>\n",
       "      <td>Moisture resistant layered sleeve heater and m...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Elias Russegger,Gerhard Schefbanker,Gernot An...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[1. A method of forming a heater assembly comp...</td>\n",
       "      <td>A method of forming a layered heater assembly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US10360916</td>\n",
       "      <td>Enhanced voiceprint authentication</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Erik Keil Perotti]</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>[1. A method, comprising:receiving a first utt...</td>\n",
       "      <td>The invention relates to a method for enhanced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US10361627</td>\n",
       "      <td>Reduction of low frequency noise in a discrete...</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Joerg Erik Goller]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. An integrated circuit, comprising:a timeba...</td>\n",
       "      <td>An integrated circuit. The integrated circuit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US10360694</td>\n",
       "      <td>Methods and devices for image loading and meth...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Binghui Chen,Xiaoming Li]</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. A method for video playback, the method co...</td>\n",
       "      <td>The present disclosure provides methods and de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US10359381</td>\n",
       "      <td>Methods and systems for determining an interna...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>19</td>\n",
       "      <td>[Steven Lewis,Matthew Biermann,Suman Pattnaik]</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>[1. A system for determining internal properti...</td>\n",
       "      <td>Systems and methods are provided to determine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US10358532</td>\n",
       "      <td>Method for producing a non-porous composite ma...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>17</td>\n",
       "      <td>[Ren&amp;#xe9; Chelle,David Nguyen,Arnaud Vilbert]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A method of making a non-porous biodegrada...</td>\n",
       "      <td>The subject matter of the present invention is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US10359462</td>\n",
       "      <td>Method and system for monitoring a condition o...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>28</td>\n",
       "      <td>[Paolo Franco Fantoni]</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>[1. A method for monitoring a condition of an ...</td>\n",
       "      <td>A method and a system are described for monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US10362635</td>\n",
       "      <td>Method and apparatus for reporting dual mode c...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>16</td>\n",
       "      <td>[Himke Van der Velde,Gert Jan Van Lieshout,Soe...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. An evolved Node B (eNB) for receiving capa...</td>\n",
       "      <td>An apparatus for communicating with a Long-Ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>US10362368</td>\n",
       "      <td>Inferring entity information in media content</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Jeromey Russell Goetz,Adam Carlson,Douglas An...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[1. A non-transitory computer-readable medium ...</td>\n",
       "      <td>Relationships and descriptions are inferred fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>US10360813</td>\n",
       "      <td>Pulsatile pump for catheter simulator</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Keita Okayama,Yasushi Sakata,Daichi Watanabe,...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[1. A pulsatile flow generating pump for a cat...</td>\n",
       "      <td>The pump (10) includes a cylinder (13) provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US10358427</td>\n",
       "      <td>Modulators of indoleamine 2,3-dioxygenase</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Pek Yoke Chong,Martha Alicia De La Rosa,Hamil...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A compound having the structure of Formula...</td>\n",
       "      <td>Provided are compounds and pharmaceutically ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>USD0854713</td>\n",
       "      <td>Light emitting diode</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>[Chun-Hung Liu,Ming-Chi Hsu]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[The ornamental design for a light-emitting di...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US10362552</td>\n",
       "      <td>Terminal device, non-transitory computer reada...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Miho Anan,Yasuaki Hyodo,Takamitsu Iriyama,Shi...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>[1. A terminal device comprising:a processor p...</td>\n",
       "      <td>A terminal device that includes a first execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>US10359524</td>\n",
       "      <td>Interactive salt model modification</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[John Linn Pixton]</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[1. A computer-implemented method for modeling...</td>\n",
       "      <td>A method for making changes to a salt model ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US10362014</td>\n",
       "      <td>Proxy authentication method and communication ...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>9</td>\n",
       "      <td>[Miwa Okabayashi]</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[1. A proxy authentication method executed by ...</td>\n",
       "      <td>A proxy authentication method executed by a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>USD0854425</td>\n",
       "      <td>Embossed container</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>[Rowdy Holstine,Jianwen Hu,Alexandre Djolakian]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[We claim the ornamental design for an embosse...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>US10357873</td>\n",
       "      <td>Portable, handheld tool having a floor plate</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>10</td>\n",
       "      <td>[Henning Schweinberger,Klaus Scholz]</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>[1. A portable, handheld tool comprising:an op...</td>\n",
       "      <td>The invention relates to a floor plate, in par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US10360200</td>\n",
       "      <td>Numbering and layout method for flow charts</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Chad Kirby]</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[1. A method for numbering flowchart elements ...</td>\n",
       "      <td>A process for numbering flowchart elements pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USD0854641</td>\n",
       "      <td>Tent</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>[Jakub Lanca]</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>[The ornamental design for a tent, as shown an...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>US10357662</td>\n",
       "      <td>Apparatus and method for irradiating a surface...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>28</td>\n",
       "      <td>[Luis De Taboada,Jackson Streeter,Scott Bradle...</td>\n",
       "      <td>284</td>\n",
       "      <td>4</td>\n",
       "      <td>[1. An apparatus for irradiating a portion of ...</td>\n",
       "      <td>An apparatus and method is provided for irradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>US10361743</td>\n",
       "      <td>Mobile terminal</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Sungjoon Hong,Kangjae Jung,Sungjung Rho,Young...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[1. A mobile terminal comprising:a case;a meta...</td>\n",
       "      <td>A mobile terminal including a case; a metal pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USD0854531</td>\n",
       "      <td>Illuminated device case for electronic communi...</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>[Allan Shoemake,Juan David Londo&amp;#xf1;o Restre...</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>[The ornamental design for an illuminated devi...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>US10356990</td>\n",
       "      <td>Water conservation apparatus and method for pr...</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>16</td>\n",
       "      <td>[Noel Lee Geren,Daniel Morgan Pruessner]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A water conservation apparatus, comprising...</td>\n",
       "      <td>A water conservation apparatus is connectable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>US10357465</td>\n",
       "      <td>Eutectic formulations of cyclobenzaprine hydro...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Seth Lederman,Marino Nebuloni]</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>[1. A eutectic comprising 65%&amp;#xb1;2% Cycloben...</td>\n",
       "      <td>The present invention relates to pharmaceutica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>US10358134</td>\n",
       "      <td>Vehicle transmission clutch engagement control...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Alexander Phillip McDonnell,Bradley Dean Ried...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[1. A method comprising:providing a vehicle tr...</td>\n",
       "      <td>A vehicle includes a transmission having a tor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>US10358278</td>\n",
       "      <td>Dispenser bag container and dispenser rack</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Jessica Tan]</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>[1. A bag container dispenser comprising:a bag...</td>\n",
       "      <td>A bag container dispenser includes a bag conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>US10361865</td>\n",
       "      <td>Signature method and system</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Eliphaz Hibshoosh,Aviad Kipnis,Nir Moshe,Alon...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>[1. A method for digitally signing blocks of d...</td>\n",
       "      <td>In one embodiment, a method, system, and appar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>US10359455</td>\n",
       "      <td>Method for detecting a defective measurement o...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Sylvain Clot,Philippe Deschamps,Christophe Li...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>[1. A method for detecting a faulty measuremen...</td>\n",
       "      <td>A system with N equations and N unknowns is ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>US10362273</td>\n",
       "      <td>Systems and methods for managing video data</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Joshua Worrill]</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A method for managing video data in a DVM ...</td>\n",
       "      <td>Described herein are systems and methods for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>US10361511</td>\n",
       "      <td>Removal delay feature for removably connected ...</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>24</td>\n",
       "      <td>[Eldhose Peter]</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>[1. An electronic device comprising:a base;an ...</td>\n",
       "      <td>An electronic device that comprises a base, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>US10360353</td>\n",
       "      <td>Execution control of computer software instruc...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Ben Chen,Amir Glaser,Roman Minkov]</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>[1. A computer-implemented method of execution...</td>\n",
       "      <td>Execution control of computer software instruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>US10360837</td>\n",
       "      <td>Bilateral driving device and tablet display</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Man Li,Xiaoping Tan,Jiehui Qin]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[1. A bilateral driving device used in a displ...</td>\n",
       "      <td>The present application discloses a bilateral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>US10359427</td>\n",
       "      <td>Dual ionophore ion selective electrode for det...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Bernard John Van Wie,Xuesong Li]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A dual ionophore ion selective electrode (...</td>\n",
       "      <td>Biosensor and method of using the biosensors f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>US10359197</td>\n",
       "      <td>Cooking range</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>27</td>\n",
       "      <td>[Eric Deng,Michael D. Mason]</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>[1. A range for cooking comprising:a) at least...</td>\n",
       "      <td>According to one embodiment, a range for cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>US10359512</td>\n",
       "      <td>Systems and methods  for stereo radar tracking</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>25</td>\n",
       "      <td>[Lang Hong,Steven Hong]</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. A method for coherent stereo radar trackin...</td>\n",
       "      <td>A method for coherent stereo radar tracking in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>US10362341</td>\n",
       "      <td>Systems and methods for sharing video with adv...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Gad Liwerant,Christopher Dodge,Guillaume Bois...</td>\n",
       "      <td>638</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. A method for sharing video over a structur...</td>\n",
       "      <td>A user can create a video segment or employ an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>US10361493</td>\n",
       "      <td>Spring loaded parallel pad clamp connectors co...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>17</td>\n",
       "      <td>[Robert Victor De France,Daniel David Dobrinsk...</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. A spring loaded parallel pad clamp connect...</td>\n",
       "      <td>A spring loaded parallel pad clamp connector i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>US10358860</td>\n",
       "      <td>Frame assembly</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Michael L. Schweiss]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>[1. A frame assembly comprising:a generally ho...</td>\n",
       "      <td>A frame assembly supporting an overhead door h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>US10360787</td>\n",
       "      <td>Discriminating patient care communications system</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>22</td>\n",
       "      <td>[Stephen R. Embree,Frederick C. Davidson,Theop...</td>\n",
       "      <td>280</td>\n",
       "      <td>6</td>\n",
       "      <td>[1. A patient care communications system of a ...</td>\n",
       "      <td>According to the present disclosure, devices, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>US10359109</td>\n",
       "      <td>Shift device</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Takafumi Kobayashi]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>[1. A shift device comprising:a lever that is ...</td>\n",
       "      <td>A shift device including: a shift body that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>US10360931</td>\n",
       "      <td>Magnetic recording apparatus</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>19</td>\n",
       "      <td>[Masaya Ohtake,Akihiko Takeo,Gaku Koizumi,Yusu...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[1. A magnetic recording apparatus comprising:...</td>\n",
       "      <td>A magnetic recording apparatus includes a disk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>US10359065</td>\n",
       "      <td>Control button retention mechanism</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Richard D. Bothmann]</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A retention combination for a tool, compri...</td>\n",
       "      <td>A button retention mechanism that removably re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>US10360744</td>\n",
       "      <td>Verified access to a monitored property</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Daniel Todd Kerzner]</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>[1. A monitoring system comprising:one or more...</td>\n",
       "      <td>A method includes receiving, by a monitoring s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>US10358699</td>\n",
       "      <td>Fabricable, high strength, oxidation resistant...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>25</td>\n",
       "      <td>[S. Krishna Srivastava,Lee Pike]</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>[1. A nickel-chromium-cobalt-molybdenum-alumin...</td>\n",
       "      <td>Ni&amp;#x2014;Cr&amp;#x2014;Co&amp;#x2014;Mo&amp;#x2014;Al bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>US10362705</td>\n",
       "      <td>Lightweight server chassis configured for modu...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>29</td>\n",
       "      <td>[Edmond I. Bailey,Walter Carver]</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[1. A lightweight server (LWS) chassis compris...</td>\n",
       "      <td>An information handling system (IHS) includes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>US10361870</td>\n",
       "      <td>Management of cryptographically secure exchang...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>17</td>\n",
       "      <td>[Arthur Carroll Chow,Milos Dunjic,Perry Aaron ...</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[1. An apparatus, comprising:a communications ...</td>\n",
       "      <td>The disclosed embodiments include processes th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>US10359583</td>\n",
       "      <td>Behind the wall optical connector with reduced...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Jimmy Jun-Fu Chang,Kazuyoshi Takano]</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>[1. A behind-the-wall optical connector compri...</td>\n",
       "      <td>A behind-the-wall optical connector an outer h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>US10362625</td>\n",
       "      <td>Apparatus and methods in a wireless communicat...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Petteri Kela,Mario Costa,Henrik Lundqvist,Xav...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>[1. A user equipment comprising:a transmitter ...</td>\n",
       "      <td>Implementations describe a user equipment, an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>US10358060</td>\n",
       "      <td>Torsionally deforming energy attenuator</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>16</td>\n",
       "      <td>[Scot Williams]</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>[1. An energy attenuating vehicle seat configu...</td>\n",
       "      <td>Methods and apparatus are provided for a devic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>US10362642</td>\n",
       "      <td>Light emitting device and light illuminating a...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Yasuo Kogure]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[1. A light emitting device, comprising:a subs...</td>\n",
       "      <td>A light emitting device (M) includes a substra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>US10357743</td>\n",
       "      <td>Oxidation catalyst for a diesel engine exhaust</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>26</td>\n",
       "      <td>[Andrew Francis Chiffey,Oliver Cooper,Christop...</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[1. An oxidation catalyst for treating an exha...</td>\n",
       "      <td>An oxidation catalyst is described for treatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>US10361341</td>\n",
       "      <td>Indium gallium nitride red light emitting diod...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Fariba Danesh,Richard P. Schneider, Jr.,Fan R...</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>[1. A red-light emitting diode, comprising:an ...</td>\n",
       "      <td>A red-light emitting diode includes an n-doped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>US10361574</td>\n",
       "      <td>Systems, devices, and methods for control of a...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Scott D. Dalton,Theodore J. Kunich]</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>[1. A method of disconnecting a power supply f...</td>\n",
       "      <td>A power supply control circuit for a portable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>USD0854523</td>\n",
       "      <td>Mobile device</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>[Sungkwon Kim,Kwanue Hong,Chungha Kim,Giha Woo]</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>[We claim the ornamental design for a mobile d...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>US10362506</td>\n",
       "      <td>Communication aggregation system, control devi...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Norio Uchida,Toru Yamada]</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>[1. A communication aggregation system compris...</td>\n",
       "      <td>A communication aggregation system according t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>US10357963</td>\n",
       "      <td>Digital printing process</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Benzion Landa,Yehoshua Sheinman,Sagi Abramovi...</td>\n",
       "      <td>781</td>\n",
       "      <td>4</td>\n",
       "      <td>[1. A printing process comprising: applying a ...</td>\n",
       "      <td>A printing process is disclosed which comprise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grant_id                                       patent_title  \\\n",
       "0    US10359846                  Wearable device gesture detection   \n",
       "1    US10360147                                Data storage layout   \n",
       "2    US10360793  Preventing vehicle accident caused by intentio...   \n",
       "3    US10358535                         Thermal interface material   \n",
       "4    US10361019  Moisture resistant layered sleeve heater and m...   \n",
       "5    US10360916                 Enhanced voiceprint authentication   \n",
       "6    US10361627  Reduction of low frequency noise in a discrete...   \n",
       "7    US10360694  Methods and devices for image loading and meth...   \n",
       "8    US10359381  Methods and systems for determining an interna...   \n",
       "9    US10358532  Method for producing a non-porous composite ma...   \n",
       "10   US10359462  Method and system for monitoring a condition o...   \n",
       "11   US10362635  Method and apparatus for reporting dual mode c...   \n",
       "12   US10362368      Inferring entity information in media content   \n",
       "13   US10360813              Pulsatile pump for catheter simulator   \n",
       "14   US10358427          Modulators of indoleamine 2,3-dioxygenase   \n",
       "15   USD0854713                               Light emitting diode   \n",
       "16   US10362552  Terminal device, non-transitory computer reada...   \n",
       "17   US10359524                Interactive salt model modification   \n",
       "18   US10362014  Proxy authentication method and communication ...   \n",
       "19   USD0854425                                 Embossed container   \n",
       "20   US10357873       Portable, handheld tool having a floor plate   \n",
       "21   US10360200        Numbering and layout method for flow charts   \n",
       "22   USD0854641                                               Tent   \n",
       "23   US10357662  Apparatus and method for irradiating a surface...   \n",
       "24   US10361743                                    Mobile terminal   \n",
       "25   USD0854531  Illuminated device case for electronic communi...   \n",
       "26   US10356990  Water conservation apparatus and method for pr...   \n",
       "27   US10357465  Eutectic formulations of cyclobenzaprine hydro...   \n",
       "28   US10358134  Vehicle transmission clutch engagement control...   \n",
       "29   US10358278         Dispenser bag container and dispenser rack   \n",
       "..          ...                                                ...   \n",
       "120  US10361865                        Signature method and system   \n",
       "121  US10359455  Method for detecting a defective measurement o...   \n",
       "122  US10362273        Systems and methods for managing video data   \n",
       "123  US10361511  Removal delay feature for removably connected ...   \n",
       "124  US10360353  Execution control of computer software instruc...   \n",
       "125  US10360837        Bilateral driving device and tablet display   \n",
       "126  US10359427  Dual ionophore ion selective electrode for det...   \n",
       "127  US10359197                                      Cooking range   \n",
       "128  US10359512     Systems and methods  for stereo radar tracking   \n",
       "129  US10362341  Systems and methods for sharing video with adv...   \n",
       "130  US10361493  Spring loaded parallel pad clamp connectors co...   \n",
       "131  US10358860                                     Frame assembly   \n",
       "132  US10360787  Discriminating patient care communications system   \n",
       "133  US10359109                                       Shift device   \n",
       "134  US10360931                       Magnetic recording apparatus   \n",
       "135  US10359065                 Control button retention mechanism   \n",
       "136  US10360744            Verified access to a monitored property   \n",
       "137  US10358699  Fabricable, high strength, oxidation resistant...   \n",
       "138  US10362705  Lightweight server chassis configured for modu...   \n",
       "139  US10361870  Management of cryptographically secure exchang...   \n",
       "140  US10359583  Behind the wall optical connector with reduced...   \n",
       "141  US10362625  Apparatus and methods in a wireless communicat...   \n",
       "142  US10358060            Torsionally deforming energy attenuator   \n",
       "143  US10362642  Light emitting device and light illuminating a...   \n",
       "144  US10357743     Oxidation catalyst for a diesel engine exhaust   \n",
       "145  US10361341  Indium gallium nitride red light emitting diod...   \n",
       "146  US10361574  Systems, devices, and methods for control of a...   \n",
       "147  USD0854523                                      Mobile device   \n",
       "148  US10362506  Communication aggregation system, control devi...   \n",
       "149  US10357963                           Digital printing process   \n",
       "\n",
       "                                                  kind number_of_claims  \\\n",
       "0    Utility Patent Grant (with a published applica...               20   \n",
       "1    Utility Patent Grant (with a published applica...               20   \n",
       "2    Utility Patent Grant (no published application...               20   \n",
       "3    Utility Patent Grant (with a published applica...               11   \n",
       "4    Utility Patent Grant (with a published applica...               20   \n",
       "5    Utility Patent Grant (with a published applica...               12   \n",
       "6    Utility Patent Grant (no published application...               20   \n",
       "7    Utility Patent Grant (with a published applica...               14   \n",
       "8    Utility Patent Grant (with a published applica...               19   \n",
       "9    Utility Patent Grant (with a published applica...               17   \n",
       "10   Utility Patent Grant (with a published applica...               28   \n",
       "11   Utility Patent Grant (with a published applica...               16   \n",
       "12   Utility Patent Grant (no published application...               20   \n",
       "13   Utility Patent Grant (with a published applica...                6   \n",
       "14   Utility Patent Grant (with a published applica...                8   \n",
       "15                                       Design Patent                1   \n",
       "16   Utility Patent Grant (with a published applica...               13   \n",
       "17   Utility Patent Grant (with a published applica...               20   \n",
       "18   Utility Patent Grant (with a published applica...                9   \n",
       "19                                       Design Patent                1   \n",
       "20   Utility Patent Grant (with a published applica...               10   \n",
       "21   Utility Patent Grant (no published application...                6   \n",
       "22                                       Design Patent                1   \n",
       "23   Utility Patent Grant (with a published applica...               28   \n",
       "24   Utility Patent Grant (with a published applica...               13   \n",
       "25                                       Design Patent                1   \n",
       "26   Utility Patent Grant (no published application...               16   \n",
       "27   Utility Patent Grant (with a published applica...               14   \n",
       "28   Utility Patent Grant (with a published applica...               20   \n",
       "29   Utility Patent Grant (with a published applica...               11   \n",
       "..                                                 ...              ...   \n",
       "120  Utility Patent Grant (with a published applica...               20   \n",
       "121  Utility Patent Grant (with a published applica...               14   \n",
       "122  Utility Patent Grant (with a published applica...               20   \n",
       "123  Utility Patent Grant (no published application...               24   \n",
       "124  Utility Patent Grant (with a published applica...               20   \n",
       "125  Utility Patent Grant (with a published applica...               11   \n",
       "126  Utility Patent Grant (with a published applica...               13   \n",
       "127  Utility Patent Grant (with a published applica...               27   \n",
       "128  Utility Patent Grant (no published application...               25   \n",
       "129  Utility Patent Grant (with a published applica...                7   \n",
       "130  Utility Patent Grant (with a published applica...               17   \n",
       "131  Utility Patent Grant (with a published applica...               12   \n",
       "132  Utility Patent Grant (with a published applica...               22   \n",
       "133  Utility Patent Grant (with a published applica...                8   \n",
       "134  Utility Patent Grant (with a published applica...               19   \n",
       "135  Utility Patent Grant (with a published applica...                4   \n",
       "136  Utility Patent Grant (no published application...               20   \n",
       "137  Utility Patent Grant (with a published applica...               25   \n",
       "138  Utility Patent Grant (with a published applica...               29   \n",
       "139  Utility Patent Grant (with a published applica...               17   \n",
       "140  Utility Patent Grant (with a published applica...                8   \n",
       "141  Utility Patent Grant (with a published applica...               12   \n",
       "142  Utility Patent Grant (no published application...               16   \n",
       "143  Utility Patent Grant (with a published applica...               20   \n",
       "144  Utility Patent Grant (with a published applica...               26   \n",
       "145  Utility Patent Grant (with a published applica...               20   \n",
       "146  Utility Patent Grant (with a published applica...               12   \n",
       "147                                      Design Patent                1   \n",
       "148  Utility Patent Grant (with a published applica...                8   \n",
       "149  Utility Patent Grant (with a published applica...                7   \n",
       "\n",
       "                                             inventors  \\\n",
       "0        [Nissanka Arachchige Bodhi Priyantha,Jie Liu]   \n",
       "1              [Kyle B. Wheeler,Timothy P. Finkbeiner]   \n",
       "2    [Eliseba Costantini,Alice Guidotti,Daniele Mor...   \n",
       "3    [Matthew Collins Weisenberger,John Davis Cradd...   \n",
       "4    [Elias Russegger,Gerhard Schefbanker,Gernot An...   \n",
       "5                                  [Erik Keil Perotti]   \n",
       "6                                  [Joerg Erik Goller]   \n",
       "7                           [Binghui Chen,Xiaoming Li]   \n",
       "8       [Steven Lewis,Matthew Biermann,Suman Pattnaik]   \n",
       "9       [Ren&#xe9; Chelle,David Nguyen,Arnaud Vilbert]   \n",
       "10                              [Paolo Franco Fantoni]   \n",
       "11   [Himke Van der Velde,Gert Jan Van Lieshout,Soe...   \n",
       "12   [Jeromey Russell Goetz,Adam Carlson,Douglas An...   \n",
       "13   [Keita Okayama,Yasushi Sakata,Daichi Watanabe,...   \n",
       "14   [Pek Yoke Chong,Martha Alicia De La Rosa,Hamil...   \n",
       "15                        [Chun-Hung Liu,Ming-Chi Hsu]   \n",
       "16   [Miho Anan,Yasuaki Hyodo,Takamitsu Iriyama,Shi...   \n",
       "17                                  [John Linn Pixton]   \n",
       "18                                   [Miwa Okabayashi]   \n",
       "19     [Rowdy Holstine,Jianwen Hu,Alexandre Djolakian]   \n",
       "20                [Henning Schweinberger,Klaus Scholz]   \n",
       "21                                        [Chad Kirby]   \n",
       "22                                       [Jakub Lanca]   \n",
       "23   [Luis De Taboada,Jackson Streeter,Scott Bradle...   \n",
       "24   [Sungjoon Hong,Kangjae Jung,Sungjung Rho,Young...   \n",
       "25   [Allan Shoemake,Juan David Londo&#xf1;o Restre...   \n",
       "26            [Noel Lee Geren,Daniel Morgan Pruessner]   \n",
       "27                     [Seth Lederman,Marino Nebuloni]   \n",
       "28   [Alexander Phillip McDonnell,Bradley Dean Ried...   \n",
       "29                                       [Jessica Tan]   \n",
       "..                                                 ...   \n",
       "120  [Eliphaz Hibshoosh,Aviad Kipnis,Nir Moshe,Alon...   \n",
       "121  [Sylvain Clot,Philippe Deschamps,Christophe Li...   \n",
       "122                                   [Joshua Worrill]   \n",
       "123                                    [Eldhose Peter]   \n",
       "124                [Ben Chen,Amir Glaser,Roman Minkov]   \n",
       "125                   [Man Li,Xiaoping Tan,Jiehui Qin]   \n",
       "126                  [Bernard John Van Wie,Xuesong Li]   \n",
       "127                       [Eric Deng,Michael D. Mason]   \n",
       "128                            [Lang Hong,Steven Hong]   \n",
       "129  [Gad Liwerant,Christopher Dodge,Guillaume Bois...   \n",
       "130  [Robert Victor De France,Daniel David Dobrinsk...   \n",
       "131                              [Michael L. Schweiss]   \n",
       "132  [Stephen R. Embree,Frederick C. Davidson,Theop...   \n",
       "133                               [Takafumi Kobayashi]   \n",
       "134  [Masaya Ohtake,Akihiko Takeo,Gaku Koizumi,Yusu...   \n",
       "135                              [Richard D. Bothmann]   \n",
       "136                              [Daniel Todd Kerzner]   \n",
       "137                   [S. Krishna Srivastava,Lee Pike]   \n",
       "138                   [Edmond I. Bailey,Walter Carver]   \n",
       "139  [Arthur Carroll Chow,Milos Dunjic,Perry Aaron ...   \n",
       "140              [Jimmy Jun-Fu Chang,Kazuyoshi Takano]   \n",
       "141  [Petteri Kela,Mario Costa,Henrik Lundqvist,Xav...   \n",
       "142                                    [Scot Williams]   \n",
       "143                                     [Yasuo Kogure]   \n",
       "144  [Andrew Francis Chiffey,Oliver Cooper,Christop...   \n",
       "145  [Fariba Danesh,Richard P. Schneider, Jr.,Fan R...   \n",
       "146               [Scott D. Dalton,Theodore J. Kunich]   \n",
       "147    [Sungkwon Kim,Kwanue Hong,Chungha Kim,Giha Woo]   \n",
       "148                         [Norio Uchida,Toru Yamada]   \n",
       "149  [Benzion Landa,Yehoshua Sheinman,Sagi Abramovi...   \n",
       "\n",
       "     citations_applicant_count  citations_examiner_count  \\\n",
       "0                            0                         2   \n",
       "1                          296                        12   \n",
       "2                            9                         5   \n",
       "3                           12                        13   \n",
       "4                            0                         9   \n",
       "5                            3                        29   \n",
       "6                            2                         5   \n",
       "7                           30                         5   \n",
       "8                           14                         9   \n",
       "9                            3                         1   \n",
       "10                          25                        10   \n",
       "11                          25                         1   \n",
       "12                           0                        17   \n",
       "13                           3                         7   \n",
       "14                           4                         1   \n",
       "15                           0                         2   \n",
       "16                           8                         9   \n",
       "17                          14                         3   \n",
       "18                           5                         2   \n",
       "19                           0                         6   \n",
       "20                          12                         4   \n",
       "21                           0                        12   \n",
       "22                           1                        15   \n",
       "23                         284                         4   \n",
       "24                           7                         3   \n",
       "25                           7                        15   \n",
       "26                          11                         1   \n",
       "27                         196                        10   \n",
       "28                           3                         6   \n",
       "29                          17                        25   \n",
       "..                         ...                       ...   \n",
       "120                          8                        11   \n",
       "121                          5                         7   \n",
       "122                        353                         1   \n",
       "123                         12                        18   \n",
       "124                          6                        12   \n",
       "125                          0                         6   \n",
       "126                          0                         1   \n",
       "127                         17                         4   \n",
       "128                         13                         5   \n",
       "129                        638                         0   \n",
       "130                         19                         5   \n",
       "131                          3                         8   \n",
       "132                        280                         6   \n",
       "133                         11                        12   \n",
       "134                          3                         7   \n",
       "135                         42                         1   \n",
       "136                          8                        11   \n",
       "137                         17                         3   \n",
       "138                          0                        14   \n",
       "139                         16                         3   \n",
       "140                        224                         2   \n",
       "141                         13                        10   \n",
       "142                         11                         5   \n",
       "143                          7                         2   \n",
       "144                         21                         2   \n",
       "145                         23                         3   \n",
       "146                         37                         1   \n",
       "147                          0                        69   \n",
       "148                         18                         8   \n",
       "149                        781                         4   \n",
       "\n",
       "                                           claims_text  \\\n",
       "0    [1. A wearable device comprising:at least one ...   \n",
       "1    [1. A system for storing data elements compris...   \n",
       "2    [1. A method for detecting and managing a vehi...   \n",
       "3    [1. A thermal interface material, comprising:a...   \n",
       "4    [1. A method of forming a heater assembly comp...   \n",
       "5    [1. A method, comprising:receiving a first utt...   \n",
       "6    [1. An integrated circuit, comprising:a timeba...   \n",
       "7    [1. A method for video playback, the method co...   \n",
       "8    [1. A system for determining internal properti...   \n",
       "9    [1. A method of making a non-porous biodegrada...   \n",
       "10   [1. A method for monitoring a condition of an ...   \n",
       "11   [1. An evolved Node B (eNB) for receiving capa...   \n",
       "12   [1. A non-transitory computer-readable medium ...   \n",
       "13   [1. A pulsatile flow generating pump for a cat...   \n",
       "14   [1. A compound having the structure of Formula...   \n",
       "15   [The ornamental design for a light-emitting di...   \n",
       "16   [1. A terminal device comprising:a processor p...   \n",
       "17   [1. A computer-implemented method for modeling...   \n",
       "18   [1. A proxy authentication method executed by ...   \n",
       "19   [We claim the ornamental design for an embosse...   \n",
       "20   [1. A portable, handheld tool comprising:an op...   \n",
       "21   [1. A method for numbering flowchart elements ...   \n",
       "22   [The ornamental design for a tent, as shown an...   \n",
       "23   [1. An apparatus for irradiating a portion of ...   \n",
       "24   [1. A mobile terminal comprising:a case;a meta...   \n",
       "25   [The ornamental design for an illuminated devi...   \n",
       "26   [1. A water conservation apparatus, comprising...   \n",
       "27   [1. A eutectic comprising 65%&#xb1;2% Cycloben...   \n",
       "28   [1. A method comprising:providing a vehicle tr...   \n",
       "29   [1. A bag container dispenser comprising:a bag...   \n",
       "..                                                 ...   \n",
       "120  [1. A method for digitally signing blocks of d...   \n",
       "121  [1. A method for detecting a faulty measuremen...   \n",
       "122  [1. A method for managing video data in a DVM ...   \n",
       "123  [1. An electronic device comprising:a base;an ...   \n",
       "124  [1. A computer-implemented method of execution...   \n",
       "125  [1. A bilateral driving device used in a displ...   \n",
       "126  [1. A dual ionophore ion selective electrode (...   \n",
       "127  [1. A range for cooking comprising:a) at least...   \n",
       "128  [1. A method for coherent stereo radar trackin...   \n",
       "129  [1. A method for sharing video over a structur...   \n",
       "130  [1. A spring loaded parallel pad clamp connect...   \n",
       "131  [1. A frame assembly comprising:a generally ho...   \n",
       "132  [1. A patient care communications system of a ...   \n",
       "133  [1. A shift device comprising:a lever that is ...   \n",
       "134  [1. A magnetic recording apparatus comprising:...   \n",
       "135  [1. A retention combination for a tool, compri...   \n",
       "136  [1. A monitoring system comprising:one or more...   \n",
       "137  [1. A nickel-chromium-cobalt-molybdenum-alumin...   \n",
       "138  [1. A lightweight server (LWS) chassis compris...   \n",
       "139  [1. An apparatus, comprising:a communications ...   \n",
       "140  [1. A behind-the-wall optical connector compri...   \n",
       "141  [1. A user equipment comprising:a transmitter ...   \n",
       "142  [1. An energy attenuating vehicle seat configu...   \n",
       "143  [1. A light emitting device, comprising:a subs...   \n",
       "144  [1. An oxidation catalyst for treating an exha...   \n",
       "145  [1. A red-light emitting diode, comprising:an ...   \n",
       "146  [1. A method of disconnecting a power supply f...   \n",
       "147  [We claim the ornamental design for a mobile d...   \n",
       "148  [1. A communication aggregation system compris...   \n",
       "149  [1. A printing process comprising: applying a ...   \n",
       "\n",
       "                                              abstract  \n",
       "0    The description relates to smart rings. One ex...  \n",
       "1    Examples of the present disclosure provide app...  \n",
       "2    A method, computer system, and a computer prog...  \n",
       "3    A flexible sheet of aligned carbon nanotubes i...  \n",
       "4    A method of forming a layered heater assembly ...  \n",
       "5    The invention relates to a method for enhanced...  \n",
       "6    An integrated circuit. The integrated circuit ...  \n",
       "7    The present disclosure provides methods and de...  \n",
       "8    Systems and methods are provided to determine ...  \n",
       "9    The subject matter of the present invention is...  \n",
       "10   A method and a system are described for monito...  \n",
       "11   An apparatus for communicating with a Long-Ter...  \n",
       "12   Relationships and descriptions are inferred fo...  \n",
       "13   The pump (10) includes a cylinder (13) provide...  \n",
       "14   Provided are compounds and pharmaceutically ac...  \n",
       "15                                                  NA  \n",
       "16   A terminal device that includes a first execut...  \n",
       "17   A method for making changes to a salt model ar...  \n",
       "18   A proxy authentication method executed by a co...  \n",
       "19                                                  NA  \n",
       "20   The invention relates to a floor plate, in par...  \n",
       "21   A process for numbering flowchart elements pop...  \n",
       "22                                                  NA  \n",
       "23   An apparatus and method is provided for irradi...  \n",
       "24   A mobile terminal including a case; a metal pl...  \n",
       "25                                                  NA  \n",
       "26   A water conservation apparatus is connectable ...  \n",
       "27   The present invention relates to pharmaceutica...  \n",
       "28   A vehicle includes a transmission having a tor...  \n",
       "29   A bag container dispenser includes a bag conta...  \n",
       "..                                                 ...  \n",
       "120  In one embodiment, a method, system, and appar...  \n",
       "121  A system with N equations and N unknowns is ge...  \n",
       "122  Described herein are systems and methods for m...  \n",
       "123  An electronic device that comprises a base, an...  \n",
       "124  Execution control of computer software instruc...  \n",
       "125  The present application discloses a bilateral ...  \n",
       "126  Biosensor and method of using the biosensors f...  \n",
       "127  According to one embodiment, a range for cooki...  \n",
       "128  A method for coherent stereo radar tracking in...  \n",
       "129  A user can create a video segment or employ an...  \n",
       "130  A spring loaded parallel pad clamp connector i...  \n",
       "131  A frame assembly supporting an overhead door h...  \n",
       "132  According to the present disclosure, devices, ...  \n",
       "133  A shift device including: a shift body that is...  \n",
       "134  A magnetic recording apparatus includes a disk...  \n",
       "135  A button retention mechanism that removably re...  \n",
       "136  A method includes receiving, by a monitoring s...  \n",
       "137  Ni&#x2014;Cr&#x2014;Co&#x2014;Mo&#x2014;Al bas...  \n",
       "138  An information handling system (IHS) includes ...  \n",
       "139  The disclosed embodiments include processes th...  \n",
       "140  A behind-the-wall optical connector an outer h...  \n",
       "141  Implementations describe a user equipment, an ...  \n",
       "142  Methods and apparatus are provided for a devic...  \n",
       "143  A light emitting device (M) includes a substra...  \n",
       "144  An oxidation catalyst is described for treatin...  \n",
       "145  A red-light emitting diode includes an n-doped...  \n",
       "146  A power supply control circuit for a portable ...  \n",
       "147                                                 NA  \n",
       "148  A communication aggregation system according t...  \n",
       "149  A printing process is disclosed which comprise...  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "\n",
    "'grant_id' : grant_id, \n",
    "'patent_title' : patent_title,\n",
    "'kind' : patent_kind, \n",
    "'number_of_claims' : number_of_claims, \n",
    "'inventors' : inventors,\n",
    "'citations_applicant_count': citations_applicant_count,\n",
    "'citations_examiner_count': citations_examiner_count,\n",
    "'claims_text': claims_text,\n",
    "'abstract': abstract\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating CSV file\n",
    "\n",
    "We use the pandas to_csv() function to convert the above dataframe to a csv file. We specify that index is False so as to not include the default index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Group017.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating json file\n",
    "\n",
    "In order to convert to json, we just used a for loop and concatenated the required data in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=open(\"Group017.json\", \"w\")\n",
    "sample.write(\"{\")\n",
    "for i in range(len(patents)-1):\n",
    "    sample.write('\"'+grant_id[i]+'\"' + \":{\" + '\"patent_title\"'+\":\"+ '\"'+ patent_title[i]+'\"'+\",\"+'\"kind\"'+\":\"+'\"'+ patent_kind[i]+'\"'+\",\"+'\"number_of_claims\"'+\":\"+ str(number_of_claims[i])+\",\"+ '\"inventors\"' +\":\"+'\"'+ inventors[i]+'\"'+\",\"+'\"citations_applicant_count\"'+\":\"+ str(citations_applicant_count[i])+\",\"+'\"citations_examiner_count\"'+\":\"+ str(citations_examiner_count[i])+\",\"+'\"claims_text\"'+\":\"+'\"'+ claims_text[i]+'\"'+\",\"+'\"abstract\"'+\":\"+ '\"'+abstract[i]+'\"'+\"},\")\n",
    "sample.write('\"'+grant_id[len(patents)-1]+'\"' + \":{\" + '\"patent_title\"'+\":\"+ '\"'+ patent_title[len(patents)-1]+'\"'+\",\"+'\"kind\"'+\":\"+'\"'+ patent_kind[len(patents)-1]+'\"'+\",\"+'\"number_of_claims\"'+\":\"+ str(number_of_claims[len(patents)-1])+\",\"+ '\"inventors\"' +\":\"+'\"'+ inventors[len(patents)-1]+'\"'+\",\"+'\"citations_applicant_count\"'+\":\"+ str(citations_applicant_count[len(patents)-1])+\",\"+'\"citations_examiner_count\"'+\":\"+ str(citations_examiner_count[len(patents)-1])+\",\"+'\"claims_text\"'+\":\"+'\"'+ claims_text[len(patents)-1]+'\"'+\",\"+'\"abstract\"'+\":\"+ '\"'+abstract[len(patents)-1]+'\"'+\"}}\")\n",
    "sample.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "This assessment measured the understanding of text file parsing techniques using Python and helped us to understand the uses of the pandas and re libraries. We were also able to improve our understanding of regular expressions, since they were used extensively in this assignment. \n",
    "Apart from this, we were able to learn and understand the formats of xml, csv and json files. \n",
    "\n",
    "The process of writing the program was long but thoroughly interesting. \n",
    "The code runs with no errors and gives the desired output. While working on this assignment we were able to implement concepts that were covered in the lectures and tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "- CSEstack. (2019). 3 Ways to Check if all Elements in List are Same [Python Code]. [online] Available at: https://www.csestack.org/python-check-if-all-elements-in-list-are-same/ [Accessed 20 Aug. 2019].\n",
    "\n",
    "- Stack Overflow. (2019). How would you make a comma-separated string from a list of strings?. [online] Available at: https://stackoverflow.com/questions/44778/how-would-you-make-a-comma-separated-string-from-a-list-of-strings/44781#44781 [Accessed 20 Aug. 2019].\n",
    "\n",
    "- Stack Overflow. (2019). What do 'lazy' and 'greedy' mean in the context of regular expressions?. [online] Available at: https://stackoverflow.com/questions/2301285/what-do-lazy-and-greedy-mean-in-the-context-of-regular-expressions [Accessed 20 Aug. 2019].\n",
    "\n",
    "- Squarespace. (2019). What is JSON?. [online] Available at: https://developers.squarespace.com/what-is-json [Accessed 20 Aug. 2019]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
